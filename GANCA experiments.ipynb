{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANCA Experimentats & Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stuff\n",
    "\n",
    "import data_helper\n",
    "import importlib\n",
    "importlib.reload(data_helper)\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from torchsummaryX import summary\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from einops import rearrange\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "import pandas as pd\n",
    "\n",
    "BLOCK2VEC_OUT_PATH = 'output/block2vec saves/block2vec 64 dim/'\n",
    "NUM_WORKERS = int(os.cpu_count() / 2)\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(BLOCK2VEC_OUT_PATH + \"representations.pkl\", 'rb') as f:\n",
    "\tembeddings_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_array = np.load(BLOCK2VEC_OUT_PATH + \"embeddings.npy\")\n",
    "embeddings_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(218, 64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding.from_pretrained(torch.tensor(embeddings_array), freeze=True)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(BLOCK2VEC_OUT_PATH + \"block2idx.pkl\", 'rb') as f:\n",
    "\tBLOCK2EMBEDDINGIDX = pickle.load(f)\n",
    "with open(BLOCK2VEC_OUT_PATH + \"idx2block.pkl\", 'rb') as f:\n",
    "    EMBEDDINGIDX2BLOCK = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_block_database = pd.read_csv('block_ids_alt.tsv', sep='\\t')\n",
    "mc_block_database = mc_block_database.filter(items=['numerical id', 'item id'])\n",
    "mc_block_database = mc_block_database.dropna(subset=[\"numerical id\"])\n",
    "MCID2BLOCK = mc_block_database.set_index('numerical id').to_dict()['item id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_helper import GANCA3DDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:175: LightningDeprecationWarning: DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\"DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d3e9b351904a4a89a6d0d66434c995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1977 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 1977 houses\n",
      "turning MC id into embedding idx\n"
     ]
    }
   ],
   "source": [
    "dm = GANCA3DDataModule(batch_size=16, num_workers=1, mcid2block = MCID2BLOCK, block2embeddingid = BLOCK2EMBEDDINGIDX)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = dm.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 32, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get one batch\n",
    "sample_batch = next(iter(train_dataloader))\n",
    "sample_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 32, 32, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(sample_batch).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "**All moved to models.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import VoxelPerceptionNet, VoxelUpdateNet, VoxelNCAModel, VoxelDiscriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voxel Perception Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_perception_net = VoxelPerceptionNet(num_in_channels=128, normal_std=0.02, num_perceptions=3, use_normal_init=True, zero_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                          Kernel Shape           Output Shape  Params  \\\n",
      "Layer                                                                   \n",
      "0_sequence.Conv3d_0  [1, 384, 3, 3, 3]  [16, 384, 32, 32, 32]   10368   \n",
      "\n",
      "                     Mult-Adds  \n",
      "Layer                           \n",
      "0_sequence.Conv3d_0  339738624  \n",
      "--------------------------------------------------------------------------------\n",
      "                         Totals\n",
      "Total params              10368\n",
      "Trainable params          10368\n",
      "Non-trainable params          0\n",
      "Mult-Adds             339738624\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "_ = summary(sample_perception_net, torch.rand(16, 128, 32, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voxel Update Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_update_net = VoxelUpdateNet(\n",
    "        num_channels = 128,\n",
    "        num_perceptions = 3,\n",
    "        channel_dims = [32, 32],\n",
    "        normal_std = 0.02,\n",
    "        use_normal_init = True,\n",
    "        zero_bias = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================\n",
      "                             Kernel Shape           Output Shape  Params  \\\n",
      "Layer                                                                      \n",
      "0_update_net.Conv3d_0  [384, 32, 1, 1, 1]   [16, 32, 32, 32, 32]  12.32k   \n",
      "1_update_net.ReLU_1                     -   [16, 32, 32, 32, 32]       -   \n",
      "2_update_net.Conv3d_2   [32, 32, 1, 1, 1]   [16, 32, 32, 32, 32]  1.056k   \n",
      "3_update_net.ReLU_3                     -   [16, 32, 32, 32, 32]       -   \n",
      "4_update_net.Conv3d_4  [32, 128, 1, 1, 1]  [16, 128, 32, 32, 32]  4.096k   \n",
      "\n",
      "                         Mult-Adds  \n",
      "Layer                               \n",
      "0_update_net.Conv3d_0  402.653184M  \n",
      "1_update_net.ReLU_1              -  \n",
      "2_update_net.Conv3d_2   33.554432M  \n",
      "3_update_net.ReLU_3              -  \n",
      "4_update_net.Conv3d_4  134.217728M  \n",
      "--------------------------------------------------------------------------------------\n",
      "                           Totals\n",
      "Total params              17.472k\n",
      "Trainable params          17.472k\n",
      "Non-trainable params          0.0\n",
      "Mult-Adds             570.425344M\n",
      "======================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sum = df.sum()\n"
     ]
    }
   ],
   "source": [
    "_ = summary(sample_update_net, sample_perception_net(torch.rand(16, 128, 32, 32, 32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VoxelNCA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_voxel_nca_model = VoxelNCAModel(\n",
    "    alpha_living_threshold = 0.1,\n",
    "    cell_fire_rate = 0.5,\n",
    "    num_perceptions = 3,\n",
    "    perception_requires_grad = True,\n",
    "    num_hidden_channels = 127,\n",
    "    normal_std = 0.0002,\n",
    "    use_normal_init = True,\n",
    "    zero_bias = True,\n",
    "    update_net_channel_dims = [32, 32]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_state = torch.rand(16, 128, 32, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================\n",
      "                                             Kernel Shape  \\\n",
      "Layer                                                       \n",
      "0_perception_net.sequence.Conv3d_0      [1, 384, 3, 3, 3]   \n",
      "1_update_network.update_net.Conv3d_0   [384, 32, 1, 1, 1]   \n",
      "2_update_network.update_net.ReLU_1                      -   \n",
      "3_update_network.update_net.Conv3d_2    [32, 32, 1, 1, 1]   \n",
      "4_update_network.update_net.ReLU_3                      -   \n",
      "5_update_network.update_net.Conv3d_4   [32, 128, 1, 1, 1]   \n",
      "6_perception_net.sequence.Conv3d_0      [1, 384, 3, 3, 3]   \n",
      "7_update_network.update_net.Conv3d_0   [384, 32, 1, 1, 1]   \n",
      "8_update_network.update_net.ReLU_1                      -   \n",
      "9_update_network.update_net.Conv3d_2    [32, 32, 1, 1, 1]   \n",
      "10_update_network.update_net.ReLU_3                     -   \n",
      "11_update_network.update_net.Conv3d_4  [32, 128, 1, 1, 1]   \n",
      "12_perception_net.sequence.Conv3d_0     [1, 384, 3, 3, 3]   \n",
      "13_update_network.update_net.Conv3d_0  [384, 32, 1, 1, 1]   \n",
      "14_update_network.update_net.ReLU_1                     -   \n",
      "15_update_network.update_net.Conv3d_2   [32, 32, 1, 1, 1]   \n",
      "16_update_network.update_net.ReLU_3                     -   \n",
      "17_update_network.update_net.Conv3d_4  [32, 128, 1, 1, 1]   \n",
      "18_perception_net.sequence.Conv3d_0     [1, 384, 3, 3, 3]   \n",
      "19_update_network.update_net.Conv3d_0  [384, 32, 1, 1, 1]   \n",
      "20_update_network.update_net.ReLU_1                     -   \n",
      "21_update_network.update_net.Conv3d_2   [32, 32, 1, 1, 1]   \n",
      "22_update_network.update_net.ReLU_3                     -   \n",
      "23_update_network.update_net.Conv3d_4  [32, 128, 1, 1, 1]   \n",
      "\n",
      "                                                Output Shape   Params  \\\n",
      "Layer                                                                   \n",
      "0_perception_net.sequence.Conv3d_0     [16, 384, 32, 32, 32]  10.368k   \n",
      "1_update_network.update_net.Conv3d_0    [16, 32, 32, 32, 32]   12.32k   \n",
      "2_update_network.update_net.ReLU_1      [16, 32, 32, 32, 32]        -   \n",
      "3_update_network.update_net.Conv3d_2    [16, 32, 32, 32, 32]   1.056k   \n",
      "4_update_network.update_net.ReLU_3      [16, 32, 32, 32, 32]        -   \n",
      "5_update_network.update_net.Conv3d_4   [16, 128, 32, 32, 32]   4.096k   \n",
      "6_perception_net.sequence.Conv3d_0     [16, 384, 32, 32, 32]        -   \n",
      "7_update_network.update_net.Conv3d_0    [16, 32, 32, 32, 32]        -   \n",
      "8_update_network.update_net.ReLU_1      [16, 32, 32, 32, 32]        -   \n",
      "9_update_network.update_net.Conv3d_2    [16, 32, 32, 32, 32]        -   \n",
      "10_update_network.update_net.ReLU_3     [16, 32, 32, 32, 32]        -   \n",
      "11_update_network.update_net.Conv3d_4  [16, 128, 32, 32, 32]        -   \n",
      "12_perception_net.sequence.Conv3d_0    [16, 384, 32, 32, 32]        -   \n",
      "13_update_network.update_net.Conv3d_0   [16, 32, 32, 32, 32]        -   \n",
      "14_update_network.update_net.ReLU_1     [16, 32, 32, 32, 32]        -   \n",
      "15_update_network.update_net.Conv3d_2   [16, 32, 32, 32, 32]        -   \n",
      "16_update_network.update_net.ReLU_3     [16, 32, 32, 32, 32]        -   \n",
      "17_update_network.update_net.Conv3d_4  [16, 128, 32, 32, 32]        -   \n",
      "18_perception_net.sequence.Conv3d_0    [16, 384, 32, 32, 32]        -   \n",
      "19_update_network.update_net.Conv3d_0   [16, 32, 32, 32, 32]        -   \n",
      "20_update_network.update_net.ReLU_1     [16, 32, 32, 32, 32]        -   \n",
      "21_update_network.update_net.Conv3d_2   [16, 32, 32, 32, 32]        -   \n",
      "22_update_network.update_net.ReLU_3     [16, 32, 32, 32, 32]        -   \n",
      "23_update_network.update_net.Conv3d_4  [16, 128, 32, 32, 32]        -   \n",
      "\n",
      "                                         Mult-Adds  \n",
      "Layer                                               \n",
      "0_perception_net.sequence.Conv3d_0     339.738624M  \n",
      "1_update_network.update_net.Conv3d_0   402.653184M  \n",
      "2_update_network.update_net.ReLU_1               -  \n",
      "3_update_network.update_net.Conv3d_2    33.554432M  \n",
      "4_update_network.update_net.ReLU_3               -  \n",
      "5_update_network.update_net.Conv3d_4   134.217728M  \n",
      "6_perception_net.sequence.Conv3d_0     339.738624M  \n",
      "7_update_network.update_net.Conv3d_0   402.653184M  \n",
      "8_update_network.update_net.ReLU_1               -  \n",
      "9_update_network.update_net.Conv3d_2    33.554432M  \n",
      "10_update_network.update_net.ReLU_3              -  \n",
      "11_update_network.update_net.Conv3d_4  134.217728M  \n",
      "12_perception_net.sequence.Conv3d_0    339.738624M  \n",
      "13_update_network.update_net.Conv3d_0  402.653184M  \n",
      "14_update_network.update_net.ReLU_1              -  \n",
      "15_update_network.update_net.Conv3d_2   33.554432M  \n",
      "16_update_network.update_net.ReLU_3              -  \n",
      "17_update_network.update_net.Conv3d_4  134.217728M  \n",
      "18_perception_net.sequence.Conv3d_0    339.738624M  \n",
      "19_update_network.update_net.Conv3d_0  402.653184M  \n",
      "20_update_network.update_net.ReLU_1              -  \n",
      "21_update_network.update_net.Conv3d_2   33.554432M  \n",
      "22_update_network.update_net.ReLU_3              -  \n",
      "23_update_network.update_net.Conv3d_4  134.217728M  \n",
      "------------------------------------------------------------------------------------------------------\n",
      "                            Totals\n",
      "Total params                27.84k\n",
      "Trainable params            27.84k\n",
      "Non-trainable params           0.0\n",
      "Mult-Adds             3.640655872G\n",
      "======================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sum = df.sum()\n"
     ]
    }
   ],
   "source": [
    "_ = summary(sample_voxel_nca_model, sample_state, steps=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voxel Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_discriminator = VoxelDiscriminator(\n",
    "    num_in_channels = 64, \n",
    "    use_sigmoid=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================================\n",
      "                                Kernel Shape          Output Shape     Params  \\\n",
      "Layer                                                                           \n",
      "0_model.Identity_0                         -  [16, 64, 32, 32, 32]          -   \n",
      "1_model.Conv3d_1           [64, 64, 4, 4, 4]  [16, 64, 16, 16, 16]   262.144k   \n",
      "2_model.BatchNorm3d_2                   [64]  [16, 64, 16, 16, 16]      128.0   \n",
      "3_model.LeakyReLU_3                        -  [16, 64, 16, 16, 16]          -   \n",
      "4_model.Conv3d_4          [64, 128, 4, 4, 4]    [16, 128, 8, 8, 8]   524.288k   \n",
      "5_model.BatchNorm3d_5                  [128]    [16, 128, 8, 8, 8]      256.0   \n",
      "6_model.LeakyReLU_6                        -    [16, 128, 8, 8, 8]          -   \n",
      "7_model.Conv3d_7         [128, 256, 4, 4, 4]    [16, 256, 4, 4, 4]  2.097152M   \n",
      "8_model.BatchNorm3d_8                  [256]    [16, 256, 4, 4, 4]      512.0   \n",
      "9_model.LeakyReLU_9                        -    [16, 256, 4, 4, 4]          -   \n",
      "10_model.Conv3d_10       [256, 512, 4, 4, 4]    [16, 512, 2, 2, 2]  8.388608M   \n",
      "11_model.BatchNorm3d_11                [512]    [16, 512, 2, 2, 2]     1.024k   \n",
      "12_model.LeakyReLU_12                      -    [16, 512, 2, 2, 2]          -   \n",
      "13_model.Conv3d_13         [512, 1, 2, 2, 2]      [16, 1, 1, 1, 1]     4.096k   \n",
      "14_model.Flatten_14                        -               [16, 1]          -   \n",
      "\n",
      "                            Mult-Adds  \n",
      "Layer                                  \n",
      "0_model.Identity_0                  -  \n",
      "1_model.Conv3d_1         1.073741824G  \n",
      "2_model.BatchNorm3d_2            64.0  \n",
      "3_model.LeakyReLU_3                 -  \n",
      "4_model.Conv3d_4          268.435456M  \n",
      "5_model.BatchNorm3d_5           128.0  \n",
      "6_model.LeakyReLU_6                 -  \n",
      "7_model.Conv3d_7          134.217728M  \n",
      "8_model.BatchNorm3d_8           256.0  \n",
      "9_model.LeakyReLU_9                 -  \n",
      "10_model.Conv3d_10         67.108864M  \n",
      "11_model.BatchNorm3d_11         512.0  \n",
      "12_model.LeakyReLU_12               -  \n",
      "13_model.Conv3d_13             4.096k  \n",
      "14_model.Flatten_14                 -  \n",
      "-------------------------------------------------------------------------------------------\n",
      "                            Totals\n",
      "Total params            11.278208M\n",
      "Trainable params        11.278208M\n",
      "Non-trainable params           0.0\n",
      "Mult-Adds             1.543508928G\n",
      "===========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sum = df.sum()\n"
     ]
    }
   ],
   "source": [
    "_ = summary(sample_discriminator, torch.rand(16,64,32,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from utils import make_seed_state\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 1.0000, 1.0000, 0.0000],\n",
       "          [0.0000, 1.0000, 1.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 1.0000, 1.0000, 0.0000],\n",
       "          [0.0000, 1.0000, 1.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.5566, 0.8054, 0.0000],\n",
       "          [0.0000, 0.0471, 0.8157, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.3396, 0.6726, 0.0000],\n",
       "          [0.0000, 0.6589, 0.1739, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_seed_state(\n",
    "    batch_size = 16,\n",
    "    num_channels = 2, \n",
    "    alpha_channel_index = 0,\n",
    "    seed_dim = (2, 2, 2), \n",
    "    world_size = (4, 4, 4)\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a8d7ae5c7f0d87e5344f9e6608bfcb3eb27eaba4a1efb346157a5f4c9c93fcf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
