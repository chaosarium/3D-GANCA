{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6Ma8GkMY4xd"
      },
      "source": [
        "# Training GANCA-3D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Downloads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsBYltuhZqzQ",
        "outputId": "ce685181-45ae-41b2-ef4c-6a446818c3ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset/filtered_houses_stats.pkl4: No such file or directory\n",
            "dataset/filtered_houses_stats.pkl: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# !wget -q https://github.com/chaosarium/3D-GANCA/raw/master/data_helper.py\n",
        "# !wget -q https://github.com/chaosarium/3D-GANCA/raw/master/utils.py\n",
        "# !wget -q https://github.com/chaosarium/3D-GANCA/raw/master/models.py\n",
        "# !wget -q https://github.com/chaosarium/3D-GANCA/raw/master/block_ids_alt.tsv\n",
        "# !wget -q https://github.com/chaosarium/3D-GANCA/raw/master/output.zip\n",
        "# !unzip -q output.zip\n",
        "# !mkdir dataset\n",
        "# !wget -q https://github.com/chaosarium/3D-GANCA/blob/master/dataset/filtered_houses_stats.pkl4 -O dataset/filtered_houses_stats.pkl4\n",
        "# !wget -q https://github.com/chaosarium/3D-GANCA/blob/master/dataset/filtered_houses_stats.pkl -O dataset/filtered_houses_stats.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXAbk29ubUCP",
        "outputId": "f295e52e-d03b-4404-fe6a-be7dd410ae0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▋                          | 10 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 20 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 30 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 40 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 51 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 58 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 527 kB 17.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 134 kB 88.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 69.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 397 kB 87.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 86.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 952 kB 77.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 51.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 73.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 79.5 MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# !pip --quiet install torchsummaryX loguru einops pytorch_lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0AuuMetY4xh",
        "outputId": "7d4500f4-10c3-48bb-931d-6ab0d43dd1d7"
      },
      "outputs": [],
      "source": [
        "# import stuff\n",
        "\n",
        "import data_helper\n",
        "import utils\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "import sys\n",
        "import pickle\n",
        "import torch\n",
        "import random\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from loguru import logger as gurulogger\n",
        "gurulogger.remove()\n",
        "gurulogger.add(sys.stdout, colorize=True, format=\"<blue>{time}</blue> <level>{message}</level>\")\n",
        "gurulogger.level(\"INFO\", color=\"<red><bold>\")\n",
        "\n",
        "\n",
        "import os\n",
        "from einops import rearrange\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "\n",
        "BLOCK2VEC_OUT_PATH = 'output/block2vec saves/block2vec 64 dim/'\n",
        "NUM_WORKERS = int(os.cpu_count() / 2)\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print('CUDNN VERSION:', torch.backends.cudnn.version())\n",
        "    print('Number CUDA Devices:', torch.cuda.device_count())\n",
        "    print('CUDA Device Name:',torch.cuda.get_device_name(0))\n",
        "    print('CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ulC-44_aY4xk"
      },
      "outputs": [],
      "source": [
        "embedding, mcid2block, block2embeddingidx, embeddingidx2block = utils.get_embedding_info(BLOCK2VEC_OUT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gErQRt4LY4xl"
      },
      "outputs": [],
      "source": [
        "from data_helper import GANCA3DDataModule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UbTQFWIfY4xm"
      },
      "outputs": [],
      "source": [
        "from models import VoxelPerceptionNet, VoxelUpdateNet, VoxelNCAModel, VoxelDiscriminator\n",
        "from pytorch_lightning import Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wrdmz_nMY4xm"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "# %tensorboard --logdir lightning_logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MM GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eELhjPZ1Y4xn"
      },
      "outputs": [],
      "source": [
        "class GANCA_MMGAN(pl.LightningModule):\n",
        "\n",
        "    def __init__(self,\n",
        "            lr = 2e-4,\n",
        "            beta1 = 0.9,\n",
        "            beta2 = 0.999,\n",
        "            batch_size = 16,\n",
        "            num_embedding_channels = 64,\n",
        "            num_hidden_channels = 63,\n",
        "            update_net_channel_dims = [32, 32],\n",
        "            embedding: torch.nn.Embedding = None,\n",
        "            step_range = [16, 20],\n",
        "        ):\n",
        "        \n",
        "        super().__init__()\n",
        "        # call this to save args to the checkpoint\n",
        "        self.save_hyperparameters()\n",
        "        \n",
        "        self.lr = lr\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.batch_size = batch_size\n",
        "        self.num_embedding_channels = num_embedding_channels\n",
        "        self.num_hidden_channels = num_hidden_channels\n",
        "        self.update_net_channel_dims = update_net_channel_dims\n",
        "        # the channels will be like [alpha, embeddings ... , hiddens ...]\n",
        "        self.num_channels = 1 + self.num_embedding_channels + self.num_hidden_channels\n",
        "        self.world_size = (32,32,32)\n",
        "        self.embedding = embedding\n",
        "        self.embedding.weight.requires_grad=False # freeze embeddings\n",
        "        self.step_range = step_range\n",
        "        \n",
        "        self.generator = VoxelNCAModel(\n",
        "            alpha_living_threshold = 0.1,\n",
        "            cell_fire_rate = 0.5,\n",
        "            num_perceptions = 3,\n",
        "            perception_requires_grad = True,\n",
        "            num_embedding_channels = self.num_embedding_channels,\n",
        "            num_hidden_channels = self.num_hidden_channels,\n",
        "            normal_std = 0.0002,\n",
        "            use_normal_init = True,\n",
        "            zero_bias = True,\n",
        "            update_net_channel_dims = self.update_net_channel_dims,\n",
        "        )\n",
        "        self.discriminator = VoxelDiscriminator(\n",
        "            num_in_channels = self.num_embedding_channels, \n",
        "            use_sigmoid=True,\n",
        "        )\n",
        "        \n",
        "        # generate some random seeds (N, channels, x, y, z)\n",
        "        self.validation_noise = self.make_seed_states(16)\n",
        "        \n",
        "    def make_seed_states(self, batch_size):\n",
        "        return utils.make_seed_state(\n",
        "            batch_size = batch_size,\n",
        "            num_channels = self.num_channels, \n",
        "            alpha_channel_index = 0,\n",
        "            seed_dim = (4, 4, 4), \n",
        "            world_size = self.world_size,\n",
        "        )\n",
        "    \n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "        \n",
        "        num_steps = random.randint(*self.step_range)\n",
        "            \n",
        "        real_houses = batch\n",
        "        type_holder = batch[0,0,0,0].to(torch.float) # this is a dummy type for creating labels\n",
        "        size_this_batch = real_houses.shape[0]\n",
        "                \n",
        "        # make noise\n",
        "        \n",
        "        seed_states = self.make_seed_states(size_this_batch).type_as(type_holder) # same batch size as those coming in\n",
        "            \n",
        "        # train generator\n",
        "        if optimizer_idx == 0:\n",
        "            \n",
        "            # generate images\n",
        "            fake_houses_states = self.generator.forward(seed_states, steps=num_steps)\n",
        "                        \n",
        "            # create ground truth result (all fake results) we want D to say the generated ones are real so they are all 1s\n",
        "            real_labels = utils.make_real_labels(size_this_batch).type_as(type_holder)\n",
        "            \n",
        "            # now get the embedding parts out of the fake states\n",
        "            fake_houses = fake_houses_states[:, 1:self.num_embedding_channels+1, :, :, :]\n",
        "            \n",
        "            # see what discriminator thinks\n",
        "            fake_predictions = self.discriminator.forward(fake_houses)\n",
        "            \n",
        "            # calculate loss\n",
        "            g_loss = F.binary_cross_entropy(fake_predictions, real_labels) # y_hat, y  \n",
        "                                    \n",
        "            self.log(\"g_loss\", g_loss.detach(), prog_bar=True, logger=True)\n",
        "\n",
        "            return g_loss\n",
        "        \n",
        "        if optimizer_idx == 1:\n",
        "            \n",
        "            # get embeddings for the real house\n",
        "            real_houses = utils.examples2embedding(real_houses, self.embedding)\n",
        "            \n",
        "            # pass in real image to D and try to make it predict all 1s\n",
        "            real_targets = utils.make_real_labels(size_this_batch).type_as(type_holder)\n",
        "            real_predictions = self.discriminator.forward(real_houses)\n",
        "            real_loss = F.binary_cross_entropy(real_predictions, real_targets)\n",
        "            # TODO fix accuracy formula\n",
        "            real_acc = torch.mean(real_predictions).item() # the average prediction. The closer to 1 the more accurate\n",
        "            \n",
        "            # meanwhile, we also want D to be able to tell that outputs from G are all fake\n",
        "            fake_targets = utils.make_fake_labels(size_this_batch).type_as(type_holder)\n",
        "            fake_houses_states = self.generator.forward(seed_states, steps=num_steps).detach() # detach so that gradients don't pass back into generator\n",
        "            fake_houses = fake_houses_states[:, 1:self.num_embedding_channels+1, :, :, :] # extract the embedding parts\n",
        "            fake_predictions = self.discriminator.forward(fake_houses)\n",
        "            fake_loss = F.binary_cross_entropy(fake_predictions, fake_targets)\n",
        "            # TODO fix accuracy formula\n",
        "            fake_acc = 1 - torch.mean(fake_predictions).item() # the 1 - average prediction. The closer to 1 the more accurate\n",
        "                        \n",
        "            # discriminator loss is the average of the two losses\n",
        "            d_loss = (real_loss + fake_loss) / 2\n",
        "            avg_acc = (real_acc + fake_acc) / 2\n",
        "                    \n",
        "            self.log(\"fake_loss\", fake_loss.detach(), prog_bar=False, logger=True)\n",
        "            self.log(\"real_loss\", real_loss.detach(), prog_bar=False, logger=True)\n",
        "            self.log(\"d_loss\", d_loss.detach(), prog_bar=True, logger=True)\n",
        "            self.log(\"real_acc\", real_acc, prog_bar=False, logger=True)\n",
        "            self.log(\"fake_acc\", fake_acc, prog_bar=False, logger=True)\n",
        "            self.log(\"avg_acc\", avg_acc, prog_bar=True, logger=True)\n",
        "\n",
        "            return d_loss\n",
        "\n",
        "    def configure_optimizers(self,):\n",
        "        # define pytorch optimizers here. return [list of optimizers], [list of LR schedulers]\n",
        "        g_optimizer = torch.optim.Adam(self.generator.parameters(), lr=self.lr, betas=(self.beta1, self.beta2))\n",
        "        d_optimizer = torch.optim.Adam(self.discriminator.parameters(), lr=self.lr, betas=(self.beta1, self.beta2))\n",
        "        return [g_optimizer, d_optimizer], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lonFxlJKY4xq"
      },
      "outputs": [],
      "source": [
        "model = GANCA_MMGAN(\n",
        "    lr = 2e-4,\n",
        "    beta1 = 0.9,\n",
        "    beta2 = 0.999,\n",
        "    batch_size = 8,\n",
        "    num_embedding_channels = 64,\n",
        "    num_hidden_channels = 63,\n",
        "    update_net_channel_dims = [16, 16],\n",
        "    embedding = embedding,\n",
        "    step_range = [16, 20],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "2bdc0941b3dc499496679c7183fbff37",
            "5ae9d82c8a094e79920bb1724cfe53e8",
            "96facbd6da40424c93f074bafcb76bbe",
            "9ecea295f69c405c93af3df43b354f75",
            "9a928ccf02ae4c668bfc2be196f31376",
            "42edc229ae79434388cea378717a9aaf",
            "a65f1f8a486f47419cab33d55d86d7f9",
            "67c0303d8a574ebe9e5b35036297b8d5",
            "9060020c253a4429bfadca4b37cb5f2c",
            "e369d4e56d89406f83db778df71ffe05",
            "c6fd5703ce2743948c5decccee2d602b"
          ]
        },
        "id": "9HO0hndNY4xr",
        "outputId": "6324c09c-c795-4879-e4fa-0fa57a25e588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset already exists\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:175: LightningDeprecationWarning: DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\n",
            "  rank_zero_deprecation(\"DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bdc0941b3dc499496679c7183fbff37",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1977 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loaded 1977 houses\n",
            "Turning MC id into embedding idx. This could take up to a minute.\n"
          ]
        }
      ],
      "source": [
        "dm = GANCA3DDataModule(batch_size=8, num_workers=1, mcid2block = mcid2block, block2embeddingid = block2embeddingidx, debug=False)\n",
        "dm.prepare_data()\n",
        "dm.setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CR1dFG7Y4xr",
        "outputId": "8b398d80-b248-4be9-a5ca-3c034df5637b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n"
          ]
        }
      ],
      "source": [
        "logger = pl.loggers.TensorBoardLogger(save_dir='lightning_logs', name='GANCA', default_hp_metric=False)\n",
        "trainer = Trainer(gpus=1, max_epochs=1, fast_dev_run=False, log_every_n_steps=1, logger=logger, profiler=\"simple\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434,
          "referenced_widgets": [
            "ee702aff0c59434fa13204508cb5d22d",
            "c3805b1dda574f99a51de0c5d55b9680",
            "a5a13ea11c644321af52864783858480",
            "d609d2a11ddc48d2b5bfb05303d090d1",
            "726aa9cc89954c079c5f95faffbd4ac9",
            "dbf6830427734779b2205e75544b5d02",
            "d7c23ef46d9e4b8ab6c4086a11d23d1c",
            "c6254117a2a34d21b9880429680304b8",
            "906bb93fea954f17aec435cdbb592bee",
            "9eb0c4b9d0884e53badf26ab9bcab9c0",
            "dba04c61834b49b79f7bfd2b669a99ba"
          ]
        },
        "id": "QdN43RM2Y4xs",
        "outputId": "d8dcb443-6a68-4de7-b08b-018b8f06dd24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:120: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
            "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:470: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
            "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Missing logger folder: lightning_logs/GANCA\n",
            "\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | embedding     | Embedding          | 14.0 K\n",
            "1 | generator     | VoxelNCAModel      | 18.8 K\n",
            "2 | discriminator | VoxelDiscriminator | 11.3 M\n",
            "-----------------------------------------------------\n",
            "11.3 M    Trainable params\n",
            "14.0 K    Non-trainable params\n",
            "11.3 M    Total params\n",
            "45.244    Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee702aff0c59434fa13204508cb5d22d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ],
      "source": [
        "trainer.fit(model, dm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## WGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GANCA_WGAN(pl.LightningModule):\n",
        "\n",
        "    def __init__(self,\n",
        "            lr = 2e-4,\n",
        "            # beta1 = 0.9,\n",
        "            # beta2 = 0.999,\n",
        "            weight_clip = 0.01, # glipping gradient in WGAN\n",
        "            batch_size = 16,\n",
        "            num_embedding_channels = 64,\n",
        "            num_hidden_channels = 63,\n",
        "            update_net_channel_dims = [32, 32],\n",
        "            embedding: torch.nn.Embedding = None,\n",
        "            step_range = [16, 20],\n",
        "        ):\n",
        "        \n",
        "        super().__init__()\n",
        "        # call this to save args to the checkpoint\n",
        "        self.save_hyperparameters()\n",
        "        \n",
        "        self.lr = lr\n",
        "        self.weight_clip = weight_clip\n",
        "        # self.beta1 = beta1\n",
        "        # self.beta2 = beta2\n",
        "        self.batch_size = batch_size\n",
        "        self.num_embedding_channels = num_embedding_channels\n",
        "        self.num_hidden_channels = num_hidden_channels\n",
        "        self.update_net_channel_dims = update_net_channel_dims\n",
        "        # the channels will be like [alpha, embeddings ... , hiddens ...]\n",
        "        self.num_channels = 1 + self.num_embedding_channels + self.num_hidden_channels\n",
        "        self.world_size = (32,32,32)\n",
        "        self.seed_size = (2,2,2)\n",
        "        self.embedding = embedding\n",
        "        self.embedding.weight.requires_grad=False # freeze embeddings\n",
        "        self.step_range = step_range\n",
        "        \n",
        "        self.generator = VoxelNCAModel(\n",
        "            alpha_living_threshold = 0.1,\n",
        "            cell_fire_rate = 0.5,\n",
        "            num_perceptions = 3,\n",
        "            perception_requires_grad = True,\n",
        "            num_embedding_channels = self.num_embedding_channels,\n",
        "            num_hidden_channels = self.num_hidden_channels,\n",
        "            normal_std = 0.0002,\n",
        "            use_normal_init = True,\n",
        "            zero_bias = True,\n",
        "            update_net_channel_dims = self.update_net_channel_dims,\n",
        "        )\n",
        "        self.discriminator = VoxelDiscriminator(\n",
        "            num_in_channels = self.num_embedding_channels, \n",
        "            use_sigmoid=False,\n",
        "        )\n",
        "        \n",
        "        # generate some random seeds (N, channels, x, y, z)\n",
        "        self.validation_noise = self.make_seed_states(16)\n",
        "        \n",
        "    def make_seed_states(self, batch_size):\n",
        "        return utils.make_seed_state(\n",
        "            batch_size = batch_size,\n",
        "            num_channels = self.num_channels, \n",
        "            alpha_channel_index = 0,\n",
        "            seed_dim = self.seed_size, \n",
        "            world_size = self.world_size,\n",
        "        )\n",
        "    \n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "                \n",
        "        num_steps = random.randint(*self.step_range)\n",
        "\n",
        "        real_houses_indices = batch\n",
        "        type_holder = batch[0,0,0,0].to(torch.float) # this is a dummy type for creating labels\n",
        "        size_this_batch = real_houses_indices.shape[0]\n",
        "                \n",
        "        # make noise\n",
        "        seed_states = self.make_seed_states(size_this_batch).type_as(type_holder) # same batch size as those coming in\n",
        "            \n",
        "        # train generator\n",
        "        if optimizer_idx == 0:\n",
        "            \n",
        "            # generate fake houses and get the embedding parts out of it\n",
        "            fake_houses_states = self.generator.forward(seed_states, steps=num_steps)\n",
        "            fake_houses = fake_houses_states[:, 1:self.num_embedding_channels+1, :, :, :]\n",
        "            \n",
        "            # train gen\n",
        "            g_loss = self.train_generator(fake_houses)              \n",
        "            self.log(\"g_loss\", g_loss.detach(), prog_bar=True, logger=True)\n",
        "            return g_loss\n",
        "        \n",
        "        if optimizer_idx == 1:\n",
        "                        \n",
        "            # get embeddings for the real house\n",
        "            real_houses = utils.examples2embedding(real_houses_indices, self.embedding)\n",
        "\n",
        "            # generate fake houses\n",
        "            fake_houses_states = self.generator.forward(seed_states, steps=num_steps).detach() # detach so that gradients don't pass back into generator\n",
        "            fake_houses = fake_houses_states[:, 1:self.num_embedding_channels+1, :, :, :] # extract the embedding parts\n",
        "            \n",
        "            # train D\n",
        "            d_loss, real_loss, fake_loss = self.train_discriminator(real_houses, fake_houses)\n",
        "\n",
        "            # logging\n",
        "            self.log(\"fake_loss\", fake_loss.detach(), prog_bar=False, logger=True)\n",
        "            self.log(\"real_loss\", real_loss.detach(), prog_bar=False, logger=True)\n",
        "            self.log(\"d_loss\", d_loss.detach(), prog_bar=True, logger=True)\n",
        "            # TODO implement on acc calculations\n",
        "            # self.log(\"real_acc\", real_acc, prog_bar=False, logger=True)\n",
        "            # self.log(\"fake_acc\", fake_acc, prog_bar=False, logger=True)\n",
        "            # self.log(\"avg_acc\", avg_acc, prog_bar=True, logger=True)\n",
        "\n",
        "            return d_loss\n",
        "\n",
        "    def train_discriminator(self, real_houses, fake_houses):\n",
        "        \n",
        "        # making sure that real and fake have same shape\n",
        "        assert real_houses.shape == fake_houses.shape\n",
        "\n",
        "        # make predictions on real houses and see what D thinks\n",
        "        real_predictions = self.discriminator.forward(real_houses)\n",
        "        # For WGAN, we no longer use binary cross entropy. There is no target here.\n",
        "        real_loss = - torch.mean(real_predictions) # maximising is the same as minimising the negative\n",
        "        \n",
        "        # see what D thinks on fake houses\n",
        "        fake_predictions = self.discriminator.forward(real_houses)\n",
        "        # once again, not BCE here\n",
        "        fake_loss = torch.mean(fake_predictions)\n",
        "        \n",
        "        # make loss the sum\n",
        "        d_loss = real_loss + fake_loss\n",
        "        \n",
        "        # clamp parameters\n",
        "        for param in self.discriminator.parameters():\n",
        "            param.data.clamp_(-self.weight_clip, self.weight_clip)\n",
        "        \n",
        "        return d_loss, real_loss, fake_loss\n",
        "    \n",
        "    def train_generator(self, fake_houses):\n",
        "        \n",
        "        # see what D thinks \n",
        "        fake_predictions = self.discriminator.forward(fake_houses)\n",
        "        \n",
        "        # calc loss. We want to maximise the prediction for this one (only doing so with G's parameters)\n",
        "        g_loss = -torch.mean(fake_predictions)\n",
        "        \n",
        "        return g_loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        n_critic = 5\n",
        "        \n",
        "        # for WGAN, use RMSprop\n",
        "        g_optimizer = torch.optim.RMSprop(self.generator.parameters(), lr=self.lr)\n",
        "        d_optimizer = torch.optim.RMSprop(self.discriminator.parameters(), lr=self.lr)\n",
        "        \n",
        "        return (\n",
        "            {\"optimizer\": g_optimizer, \"frequency\": 1},\n",
        "            {\"optimizer\": d_optimizer, \"frequency\": n_critic}\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = GANCA_WGAN(\n",
        "    lr = 2e-4,\n",
        "    weight_clip = 0.01,\n",
        "    batch_size = 2,\n",
        "    num_embedding_channels = 64,\n",
        "    num_hidden_channels = 63,\n",
        "    update_net_channel_dims = [8, 8],\n",
        "    embedding = embedding,\n",
        "    step_range = [1, 3],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "2bdc0941b3dc499496679c7183fbff37",
            "5ae9d82c8a094e79920bb1724cfe53e8",
            "96facbd6da40424c93f074bafcb76bbe",
            "9ecea295f69c405c93af3df43b354f75",
            "9a928ccf02ae4c668bfc2be196f31376",
            "42edc229ae79434388cea378717a9aaf",
            "a65f1f8a486f47419cab33d55d86d7f9",
            "67c0303d8a574ebe9e5b35036297b8d5",
            "9060020c253a4429bfadca4b37cb5f2c",
            "e369d4e56d89406f83db778df71ffe05",
            "c6fd5703ce2743948c5decccee2d602b"
          ]
        },
        "id": "9HO0hndNY4xr",
        "outputId": "6324c09c-c795-4879-e4fa-0fa57a25e588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset already exists\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:175: LightningDeprecationWarning: DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\n",
            "  rank_zero_deprecation(\"DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "701ead6808cd4f08a64380af92d5350d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1977 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loaded 1977 houses\n",
            "Turning MC id into embedding idx. This could take up to a minute.\n"
          ]
        }
      ],
      "source": [
        "dm = GANCA3DDataModule(batch_size=2, num_workers=1, mcid2block = mcid2block, block2embeddingid = block2embeddingidx, debug=True)\n",
        "dm.prepare_data()\n",
        "dm.setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CR1dFG7Y4xr",
        "outputId": "8b398d80-b248-4be9-a5ca-3c034df5637b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n"
          ]
        }
      ],
      "source": [
        "logger = pl.loggers.TensorBoardLogger(save_dir='lightning_logs', name='GANCA', default_hp_metric=False)\n",
        "trainer = Trainer(gpus=0, max_epochs=2, fast_dev_run=False, log_every_n_steps=1, logger=logger, profiler=\"simple\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434,
          "referenced_widgets": [
            "ee702aff0c59434fa13204508cb5d22d",
            "c3805b1dda574f99a51de0c5d55b9680",
            "a5a13ea11c644321af52864783858480",
            "d609d2a11ddc48d2b5bfb05303d090d1",
            "726aa9cc89954c079c5f95faffbd4ac9",
            "dbf6830427734779b2205e75544b5d02",
            "d7c23ef46d9e4b8ab6c4086a11d23d1c",
            "c6254117a2a34d21b9880429680304b8",
            "906bb93fea954f17aec435cdbb592bee",
            "9eb0c4b9d0884e53badf26ab9bcab9c0",
            "dba04c61834b49b79f7bfd2b669a99ba"
          ]
        },
        "id": "QdN43RM2Y4xs",
        "outputId": "d8dcb443-6a68-4de7-b08b-018b8f06dd24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:120: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
            "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n",
            "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
            "  rank_zero_deprecation(\n",
            "\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | embedding     | Embedding          | 14.0 K\n",
            "1 | generator     | VoxelNCAModel      | 14.5 K\n",
            "2 | discriminator | VoxelDiscriminator | 11.3 M\n",
            "-----------------------------------------------------\n",
            "11.3 M    Trainable params\n",
            "14.0 K    Non-trainable params\n",
            "11.3 M    Total params\n",
            "45.227    Total estimated model params size (MB)\n",
            "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/8 [00:00<?, ?it/s] \u001b[34m2022-03-03T12:01:51.444992+0800\u001b[0m \u001b[31m\u001b[1mtraining step with optimizer_idx 0\u001b[0m\n",
            "\u001b[34m2022-03-03T12:01:51.450620+0800\u001b[0m \u001b[31m\u001b[1mtraining G\u001b[0m\n",
            "Epoch 0:  12%|█▎        | 1/8 [00:03<00:25,  3.60s/it, loss=-0.0409, v_num=4, g_loss=-.0409]\u001b[34m2022-03-03T12:01:52.942144+0800\u001b[0m \u001b[31m\u001b[1mtraining step with optimizer_idx 1\u001b[0m\n",
            "\u001b[34m2022-03-03T12:01:52.943449+0800\u001b[0m \u001b[31m\u001b[1mtraining D\u001b[0m\n",
            "Epoch 0:  25%|██▌       | 2/8 [00:04<00:13,  2.31s/it, loss=-0.0205, v_num=4, g_loss=-.0409, d_loss=0.000]\u001b[34m2022-03-03T12:01:53.832096+0800\u001b[0m \u001b[31m\u001b[1mtraining step with optimizer_idx 1\u001b[0m\n",
            "\u001b[34m2022-03-03T12:01:53.834149+0800\u001b[0m \u001b[31m\u001b[1mtraining D\u001b[0m\n",
            "Epoch 0:  38%|███▊      | 3/8 [00:05<00:09,  1.96s/it, loss=-0.0136, v_num=4, g_loss=-.0409, d_loss=0.000]\u001b[34m2022-03-03T12:01:55.073479+0800\u001b[0m \u001b[31m\u001b[1mtraining step with optimizer_idx 1\u001b[0m\n",
            "\u001b[34m2022-03-03T12:01:55.075047+0800\u001b[0m \u001b[31m\u001b[1mtraining D\u001b[0m\n",
            "Epoch 0:  50%|█████     | 4/8 [00:06<00:06,  1.72s/it, loss=-0.0102, v_num=4, g_loss=-.0409, d_loss=0.000]\u001b[34m2022-03-03T12:01:56.070933+0800\u001b[0m \u001b[31m\u001b[1mtraining step with optimizer_idx 1\u001b[0m\n",
            "\u001b[34m2022-03-03T12:01:56.072363+0800\u001b[0m \u001b[31m\u001b[1mtraining D\u001b[0m\n",
            "Epoch 0:  62%|██████▎   | 5/8 [00:07<00:04,  1.54s/it, loss=-0.00818, v_num=4, g_loss=-.0409, d_loss=0.000]\u001b[34m2022-03-03T12:01:56.897662+0800\u001b[0m \u001b[31m\u001b[1mtraining step with optimizer_idx 1\u001b[0m\n",
            "\u001b[34m2022-03-03T12:01:56.898886+0800\u001b[0m \u001b[31m\u001b[1mtraining D\u001b[0m\n",
            "Epoch 0:  75%|███████▌  | 6/8 [00:08<00:02,  1.47s/it, loss=-0.00682, v_num=4, g_loss=-.0409, d_loss=0.000]\u001b[34m2022-03-03T12:01:58.023819+0800\u001b[0m \u001b[31m\u001b[1mtraining step with optimizer_idx 0\u001b[0m\n",
            "\u001b[34m2022-03-03T12:01:58.025562+0800\u001b[0m \u001b[31m\u001b[1mtraining G\u001b[0m\n",
            "Epoch 0:  88%|████████▊ | 7/8 [00:10<00:01,  1.53s/it, loss=-0.00584, v_num=4, g_loss=3.4e-5, d_loss=0.000]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ],
      "source": [
        "trainer.fit(model, dm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## WGAN-GP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GANCA_WGANGP(pl.LightningModule):\n",
        "\n",
        "    def __init__(self,\n",
        "            lr = 0.0001,\n",
        "            beta1 = 0,\n",
        "            beta2 = 0.9,\n",
        "            n_critic = 5,\n",
        "            lambda_gp = 10,\n",
        "            weight_clip = 0.01,\n",
        "            batch_size = 16,\n",
        "            num_embedding_channels = 64,\n",
        "            num_hidden_channels = 63,\n",
        "            update_net_channel_dims = [32, 32],\n",
        "            embedding: torch.nn.Embedding = None,\n",
        "            step_range = [16, 20],\n",
        "        ):\n",
        "        \n",
        "        super().__init__()\n",
        "        # call this to save args to the checkpoint\n",
        "        self.save_hyperparameters()\n",
        "        \n",
        "        self.lr = lr\n",
        "        self.weight_clip = weight_clip\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.n_critic = n_critic\n",
        "        self.lambda_gp = lambda_gp\n",
        "        self.batch_size = batch_size\n",
        "        self.num_embedding_channels = num_embedding_channels\n",
        "        self.num_hidden_channels = num_hidden_channels\n",
        "        self.update_net_channel_dims = update_net_channel_dims\n",
        "        # the channels will be like [alpha, embeddings ... , hiddens ...]\n",
        "        self.num_channels = 1 + self.num_embedding_channels + self.num_hidden_channels\n",
        "        self.world_size = (32,32,32)\n",
        "        self.seed_size = (2,2,2)\n",
        "        self.embedding = embedding\n",
        "        self.embedding.weight.requires_grad=False # freeze embeddings\n",
        "        self.step_range = step_range\n",
        "        \n",
        "        self.generator = VoxelNCAModel(\n",
        "            alpha_living_threshold = 0.1,\n",
        "            cell_fire_rate = 0.5,\n",
        "            num_perceptions = 3,\n",
        "            perception_requires_grad = True,\n",
        "            num_embedding_channels = self.num_embedding_channels,\n",
        "            num_hidden_channels = self.num_hidden_channels,\n",
        "            normal_std = 0.0002,\n",
        "            use_normal_init = True,\n",
        "            zero_bias = True,\n",
        "            update_net_channel_dims = self.update_net_channel_dims,\n",
        "        )\n",
        "        self.discriminator = VoxelDiscriminator(\n",
        "            num_in_channels = self.num_embedding_channels, \n",
        "            use_sigmoid=False,\n",
        "        )\n",
        "        \n",
        "        # generate some random seeds (N, channels, x, y, z)\n",
        "        self.validation_noise = self.make_seed_states(16)\n",
        "        \n",
        "    def make_seed_states(self, batch_size):\n",
        "        return utils.make_seed_state(\n",
        "            batch_size = batch_size,\n",
        "            num_channels = self.num_channels, \n",
        "            alpha_channel_index = 0,\n",
        "            seed_dim = self.seed_size, \n",
        "            world_size = self.world_size,\n",
        "        )\n",
        "    \n",
        "    def compute_gradient_penalty(self, real_samples, fake_samples):\n",
        "        # Random weight term for interpolation between real and fake samples. We get a tensor of shape (N, 1, 1, 1, 1)\n",
        "        alpha = torch.Tensor(np.random.random((real_samples.size(0), 1, 1, 1, 1))).to(self.device)\n",
        "        # Get random interpolation between real and fake samples\n",
        "        interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
        "        interpolates = interpolates.to(self.device)\n",
        "        # calc predictions for interpolated samples\n",
        "        interpolates_predictions = self.discriminator.forward(interpolates)\n",
        "        fake = torch.Tensor(real_samples.shape[0], 1).fill_(1.0).to(self.device)\n",
        "        # Get gradient w.r.t. interpolates\n",
        "        gradients = torch.autograd.grad(\n",
        "            outputs=interpolates_predictions,\n",
        "            inputs=interpolates,\n",
        "            grad_outputs=fake,\n",
        "            create_graph=True,\n",
        "            retain_graph=True,\n",
        "            only_inputs=True,\n",
        "        )[0]\n",
        "        gradients = gradients.view(gradients.size(0), -1).to(self.device)\n",
        "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "        return gradient_penalty\n",
        "\n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "        \n",
        "        num_steps = random.randint(*self.step_range)\n",
        "\n",
        "        real_houses_indices = batch\n",
        "        type_holder = batch[0,0,0,0].to(torch.float) # this is a dummy type for creating labels\n",
        "        size_this_batch = real_houses_indices.shape[0]\n",
        "                \n",
        "        # make noise\n",
        "        seed_states = self.make_seed_states(size_this_batch).type_as(type_holder) # same batch size as those coming in\n",
        "            \n",
        "        # train generator\n",
        "        if optimizer_idx == 0:\n",
        "\n",
        "            # generate fake houses and get the embedding parts out of it\n",
        "            fake_houses_states = self.generator.forward(seed_states, steps=num_steps)\n",
        "            fake_houses = fake_houses_states[:, 1:self.num_embedding_channels+1, :, :, :]\n",
        "            \n",
        "            # train gen\n",
        "            g_loss = self.train_generator(fake_houses)  \n",
        "                        \n",
        "            self.log(\"g_loss\", g_loss.detach(), prog_bar=True, logger=True)\n",
        "            return g_loss\n",
        "        \n",
        "        if optimizer_idx == 1:\n",
        "            \n",
        "            # get embeddings for the real house\n",
        "            real_houses = utils.examples2embedding(real_houses_indices, self.embedding)\n",
        "\n",
        "            # generate fake houses\n",
        "            fake_houses_states = self.generator.forward(seed_states, steps=num_steps).detach() # detach so that gradients don't pass back into generator\n",
        "            fake_houses = fake_houses_states[:, 1:self.num_embedding_channels+1, :, :, :] # extract the embedding parts\n",
        "            \n",
        "            # train D\n",
        "            d_loss = self.train_discriminator(real_houses, fake_houses)\n",
        "\n",
        "            # logging\n",
        "            self.log(\"d_loss\", d_loss.detach(), prog_bar=True, logger=True)\n",
        "            return d_loss\n",
        "\n",
        "    def train_discriminator(self, real_houses, fake_houses):\n",
        "        assert real_houses.shape == fake_houses.shape\n",
        "\n",
        "        real_predictions = self.discriminator.forward(real_houses)\n",
        "        fake_predictions = self.discriminator.forward(real_houses)\n",
        "        \n",
        "        gradient_penalty = self.compute_gradient_penalty(real_houses.data, fake_houses.data)\n",
        "                \n",
        "        d_loss = -torch.mean(real_predictions) + torch.mean(fake_predictions) + self.lambda_gp * gradient_penalty\n",
        "                \n",
        "        return d_loss\n",
        "    \n",
        "    def train_generator(self, fake_houses):\n",
        "        # see what D thinks \n",
        "        fake_predictions = self.discriminator.forward(fake_houses)\n",
        "        \n",
        "        # calc loss. We want to maximise the prediction for this one (only doing so with G's parameters)\n",
        "        g_loss = -torch.mean(fake_predictions)\n",
        "        \n",
        "        return g_loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \n",
        "        g_optimizer = torch.optim.Adam(self.generator.parameters(), lr=self.lr, betas=(self.beta1, self.beta2))\n",
        "        d_optimizer = torch.optim.Adam(self.discriminator.parameters(), lr=self.lr, betas=(self.beta1, self.beta2))\n",
        "        \n",
        "        return [\n",
        "            {\"optimizer\": g_optimizer, \"frequency\": 1},\n",
        "            {\"optimizer\": d_optimizer, \"frequency\": self.n_critic},\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = GANCA_WGANGP(\n",
        "    lr = 0.0001,\n",
        "    beta1 = 0,\n",
        "    beta2 = 0.9,\n",
        "    n_critic = 5,\n",
        "    lambda_gp = 10,\n",
        "    weight_clip = 0.01,\n",
        "    batch_size = 2,\n",
        "    num_embedding_channels = 64,\n",
        "    num_hidden_channels = 63,\n",
        "    update_net_channel_dims = [16, 16],\n",
        "    embedding = embedding,\n",
        "    step_range = [16, 20],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "2bdc0941b3dc499496679c7183fbff37",
            "5ae9d82c8a094e79920bb1724cfe53e8",
            "96facbd6da40424c93f074bafcb76bbe",
            "9ecea295f69c405c93af3df43b354f75",
            "9a928ccf02ae4c668bfc2be196f31376",
            "42edc229ae79434388cea378717a9aaf",
            "a65f1f8a486f47419cab33d55d86d7f9",
            "67c0303d8a574ebe9e5b35036297b8d5",
            "9060020c253a4429bfadca4b37cb5f2c",
            "e369d4e56d89406f83db778df71ffe05",
            "c6fd5703ce2743948c5decccee2d602b"
          ]
        },
        "id": "9HO0hndNY4xr",
        "outputId": "6324c09c-c795-4879-e4fa-0fa57a25e588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset already exists\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:175: LightningDeprecationWarning: DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\n",
            "  rank_zero_deprecation(\"DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "048b0457f25644658343e3e9888ce3db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1977 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loaded 1977 houses\n",
            "Turning MC id into embedding idx. This could take up to a minute.\n",
            "Done with that.\n"
          ]
        }
      ],
      "source": [
        "dm = GANCA3DDataModule(batch_size=2, num_workers=1, mcid2block = mcid2block, block2embeddingid = block2embeddingidx, debug=True)\n",
        "dm.prepare_data()\n",
        "dm.setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CR1dFG7Y4xr",
        "outputId": "8b398d80-b248-4be9-a5ca-3c034df5637b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n"
          ]
        }
      ],
      "source": [
        "logger = pl.loggers.TensorBoardLogger(save_dir='lightning_logs', name='GANCA', default_hp_metric=False)\n",
        "trainer = Trainer(gpus=0, max_epochs=8, fast_dev_run=False, log_every_n_steps=1, logger=logger, profiler=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434,
          "referenced_widgets": [
            "ee702aff0c59434fa13204508cb5d22d",
            "c3805b1dda574f99a51de0c5d55b9680",
            "a5a13ea11c644321af52864783858480",
            "d609d2a11ddc48d2b5bfb05303d090d1",
            "726aa9cc89954c079c5f95faffbd4ac9",
            "dbf6830427734779b2205e75544b5d02",
            "d7c23ef46d9e4b8ab6c4086a11d23d1c",
            "c6254117a2a34d21b9880429680304b8",
            "906bb93fea954f17aec435cdbb592bee",
            "9eb0c4b9d0884e53badf26ab9bcab9c0",
            "dba04c61834b49b79f7bfd2b669a99ba"
          ]
        },
        "id": "QdN43RM2Y4xs",
        "outputId": "d8dcb443-6a68-4de7-b08b-018b8f06dd24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:120: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
            "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n",
            "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
            "  rank_zero_deprecation(\n",
            "\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | embedding     | Embedding          | 14.0 K\n",
            "1 | generator     | VoxelNCAModel      | 18.8 K\n",
            "2 | discriminator | VoxelDiscriminator | 11.3 M\n",
            "-----------------------------------------------------\n",
            "11.3 M    Trainable params\n",
            "14.0 K    Non-trainable params\n",
            "11.3 M    Total params\n",
            "45.244    Total estimated model params size (MB)\n",
            "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:  25%|██▌       | 1/4 [00:23<01:11, 23.91s/it, loss=0.658, v_num=5, g_loss=0.658]\u001b[34m2022-03-03T14:09:53.074093+0800\u001b[0m \u001b[31m\u001b[1mgradient_penalty calculated to be 64.43315887451172\u001b[0m\n",
            "Epoch 0:  50%|█████     | 2/4 [00:33<00:33, 16.98s/it, loss=322, v_num=5, g_loss=0.658, d_loss=644.0]\u001b[34m2022-03-03T14:10:03.014123+0800\u001b[0m \u001b[31m\u001b[1mgradient_penalty calculated to be 14.945566177368164\u001b[0m\n",
            "Epoch 0:  75%|███████▌  | 3/4 [00:43<00:14, 14.63s/it, loss=265, v_num=5, g_loss=0.658, d_loss=149.0]\u001b[34m2022-03-03T14:10:16.508604+0800\u001b[0m \u001b[31m\u001b[1mgradient_penalty calculated to be 12.260957717895508\u001b[0m\n",
            "Epoch 1:  25%|██▌       | 1/4 [00:26<01:20, 26.96s/it, loss=183, v_num=5, g_loss=0.331, d_loss=123.0]\u001b[34m2022-03-03T14:10:52.053256+0800\u001b[0m \u001b[31m\u001b[1mgradient_penalty calculated to be 1.7487647533416748\u001b[0m\n",
            "Epoch 1:  50%|█████     | 2/4 [00:35<00:35, 17.65s/it, loss=156, v_num=5, g_loss=0.331, d_loss=17.50]\u001b[34m2022-03-03T14:11:00.636030+0800\u001b[0m \u001b[31m\u001b[1mgradient_penalty calculated to be 0.9058696031570435\u001b[0m\n",
            "Epoch 1:  75%|███████▌  | 3/4 [00:43<00:14, 14.61s/it, loss=135, v_num=5, g_loss=0.331, d_loss=9.060]\u001b[34m2022-03-03T14:11:14.210115+0800\u001b[0m \u001b[31m\u001b[1mgradient_penalty calculated to be 12.710108757019043\u001b[0m\n",
            "Epoch 2:  25%|██▌       | 1/4 [00:25<01:15, 25.14s/it, loss=119, v_num=5, g_loss=0.242, d_loss=127.0]\u001b[34m2022-03-03T14:11:48.241169+0800\u001b[0m \u001b[31m\u001b[1mgradient_penalty calculated to be 2.2887630462646484\u001b[0m\n",
            "Epoch 2:  50%|█████     | 2/4 [00:33<00:33, 16.89s/it, loss=109, v_num=5, g_loss=0.242, d_loss=22.90]\u001b[34m2022-03-03T14:11:57.129792+0800\u001b[0m \u001b[31m\u001b[1mgradient_penalty calculated to be 0.25533193349838257\u001b[0m\n",
            "Epoch 2:  75%|███████▌  | 3/4 [00:42<00:14, 14.20s/it, loss=99.7, v_num=5, g_loss=0.242, d_loss=2.550]\u001b[34m2022-03-03T14:12:10.723777+0800\u001b[0m \u001b[31m\u001b[1mgradient_penalty calculated to be 0.02061302587389946\u001b[0m\n",
            "Epoch 3:  25%|██▌       | 1/4 [00:27<01:21, 27.29s/it, loss=84.4, v_num=5, g_loss=0.226, d_loss=0.206]\u001b[34m2022-03-03T14:12:46.492155+0800\u001b[0m \u001b[31m\u001b[1mgradient_penalty calculated to be 0.24087628722190857\u001b[0m\n",
            "Epoch 3:  50%|█████     | 2/4 [00:35<00:35, 17.80s/it, loss=78.5, v_num=5, g_loss=0.226, d_loss=2.410]\u001b[34m2022-03-03T14:12:55.696448+0800\u001b[0m \u001b[31m\u001b[1mgradient_penalty calculated to be 0.05557752028107643\u001b[0m\n",
            "Epoch 3:  75%|███████▌  | 3/4 [00:44<00:14, 14.91s/it, loss=73.3, v_num=5, g_loss=0.226, d_loss=0.556]\u001b[34m2022-03-03T14:13:10.449426+0800\u001b[0m \u001b[31m\u001b[1mgradient_penalty calculated to be 0.21209664642810822\u001b[0m\n",
            "Epoch 4:  25%|██▌       | 1/4 [00:23<01:10, 23.34s/it, loss=64.9, v_num=5, g_loss=0.227, d_loss=2.120]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ],
      "source": [
        "trainer.fit(model, dm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja1BsY__Y4xs"
      },
      "source": [
        "## Debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rC-0waBoe_3E",
        "outputId": "5e7bc42d-9730-46e5-b93d-a1365c01bd27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset already exists\n",
            "Extracting dataset to dataset/house_data\n"
          ]
        }
      ],
      "source": [
        "data_helper.download_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20w5XcifY4xt"
      },
      "outputs": [],
      "source": [
        "sample_state = torch.rand(1, 128, 32, 32, 32)\n",
        "sample_seed_state = utils.make_seed_state(\n",
        "    batch_size = 1,\n",
        "    num_channels = 128, \n",
        "    alpha_channel_index = 0,\n",
        "    seed_dim = (4, 4, 4), \n",
        "    world_size = (32,32,32),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rycvOOifY4xt",
        "outputId": "23325f53-7040-4b26-cadb-97b1404b6bba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m2022-02-28T20:32:09.898136+0800\u001b[0m \u001b[31m\u001b[1mit's shape torch.Size([1, 128, 32, 32, 32]) coming in to the perception net\u001b[0m\n",
            "\u001b[34m2022-02-28T20:32:10.059550+0800\u001b[0m \u001b[33m\u001b[1mit's shape torch.Size([1, 384, 32, 32, 32]) coming in to the update net\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(2097196.2500, grad_fn=<SumBackward0>)"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# before train\n",
        "out1 = model.generator.forward(sample_state, steps=1)\n",
        "torch.sum(out1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCDTnkitY4xu",
        "outputId": "22842b52-394d-4232-ca94-d5ae3779cb33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m2022-02-28T20:32:54.688500+0800\u001b[0m \u001b[31m\u001b[1mit's shape torch.Size([1, 128, 32, 32, 32]) coming in to the perception net\u001b[0m\n",
            "\u001b[34m2022-02-28T20:32:54.819261+0800\u001b[0m \u001b[33m\u001b[1mit's shape torch.Size([1, 384, 32, 32, 32]) coming in to the update net\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(2097196.2500, grad_fn=<SumBackward0>)"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# after train\n",
        "out3 = model.generator.forward(sample_state, steps=1)\n",
        "torch.sum(out3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CcZAcnsY4xu",
        "outputId": "26bcf16d-c32d-4dde-96d6-57dd690ccd3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.equal(out1, out3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oWz2Bx62Y4xu",
        "outputId": "d3d6b648-3553-4694-8b7f-bea9d5069c56"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'sample_state' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/tt/63g2nkx15fl855gr711x66540000gn/T/ipykernel_55718/4122752455.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sample_state' is not defined"
          ]
        }
      ],
      "source": [
        "out2 = model.generator.forward(sample_state, steps=8)\n",
        "torch.sum(out2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "Copy of GANCA train.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "0228fee4d25496bb422a7e0c363e636da60e8258e4b70dda8036e2defd0af2d7"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2bdc0941b3dc499496679c7183fbff37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96facbd6da40424c93f074bafcb76bbe",
              "IPY_MODEL_9ecea295f69c405c93af3df43b354f75",
              "IPY_MODEL_9a928ccf02ae4c668bfc2be196f31376"
            ],
            "layout": "IPY_MODEL_5ae9d82c8a094e79920bb1724cfe53e8"
          }
        },
        "42edc229ae79434388cea378717a9aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ae9d82c8a094e79920bb1724cfe53e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67c0303d8a574ebe9e5b35036297b8d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "726aa9cc89954c079c5f95faffbd4ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dba04c61834b49b79f7bfd2b669a99ba",
            "placeholder": "​",
            "style": "IPY_MODEL_9eb0c4b9d0884e53badf26ab9bcab9c0",
            "value": " 100/200 [03:06&lt;03:06,  1.86s/it, loss=5.49, v_num=0, g_loss=10.90, d_loss=3.16e-5, avg_acc=1.000]"
          }
        },
        "9060020c253a4429bfadca4b37cb5f2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "906bb93fea954f17aec435cdbb592bee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96facbd6da40424c93f074bafcb76bbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a65f1f8a486f47419cab33d55d86d7f9",
            "placeholder": "​",
            "style": "IPY_MODEL_42edc229ae79434388cea378717a9aaf",
            "value": "100%"
          }
        },
        "9a928ccf02ae4c668bfc2be196f31376": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6fd5703ce2743948c5decccee2d602b",
            "placeholder": "​",
            "style": "IPY_MODEL_e369d4e56d89406f83db778df71ffe05",
            "value": " 1977/1977 [00:01&lt;00:00, 1319.86it/s]"
          }
        },
        "9eb0c4b9d0884e53badf26ab9bcab9c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ecea295f69c405c93af3df43b354f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9060020c253a4429bfadca4b37cb5f2c",
            "max": 1977,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67c0303d8a574ebe9e5b35036297b8d5",
            "value": 1977
          }
        },
        "a5a13ea11c644321af52864783858480": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7c23ef46d9e4b8ab6c4086a11d23d1c",
            "placeholder": "​",
            "style": "IPY_MODEL_dbf6830427734779b2205e75544b5d02",
            "value": "Epoch 0:  50%"
          }
        },
        "a65f1f8a486f47419cab33d55d86d7f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3805b1dda574f99a51de0c5d55b9680": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "c6254117a2a34d21b9880429680304b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6fd5703ce2743948c5decccee2d602b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d609d2a11ddc48d2b5bfb05303d090d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_906bb93fea954f17aec435cdbb592bee",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6254117a2a34d21b9880429680304b8",
            "value": 100
          }
        },
        "d7c23ef46d9e4b8ab6c4086a11d23d1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dba04c61834b49b79f7bfd2b669a99ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbf6830427734779b2205e75544b5d02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e369d4e56d89406f83db778df71ffe05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee702aff0c59434fa13204508cb5d22d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5a13ea11c644321af52864783858480",
              "IPY_MODEL_d609d2a11ddc48d2b5bfb05303d090d1",
              "IPY_MODEL_726aa9cc89954c079c5f95faffbd4ac9"
            ],
            "layout": "IPY_MODEL_c3805b1dda574f99a51de0c5d55b9680"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
