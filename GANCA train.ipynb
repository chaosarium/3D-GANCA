{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6Ma8GkMY4xd"
   },
   "source": [
    "# Training GANCA-3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable pytorch tpu spport on colab\n",
    "# !pip --quiet install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
    "# !pip --quiet install torch==1.9 torchtext==0.10 torchvision==0.10 torchaudio==0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KsBYltuhZqzQ",
    "outputId": "ce685181-45ae-41b2-ef4c-6a446818c3ab"
   },
   "outputs": [],
   "source": [
    "# !wget -q https://github.com/chaosarium/3D-GANCA/raw/master/data_helper.py\n",
    "# !wget -q https://github.com/chaosarium/3D-GANCA/raw/master/utils.py\n",
    "# !wget -q https://github.com/chaosarium/3D-GANCA/raw/master/models.py\n",
    "# !wget -q https://github.com/chaosarium/3D-GANCA/raw/master/block_ids_alt.tsv\n",
    "# !wget -q https://github.com/chaosarium/3D-GANCA/raw/master/output.zip\n",
    "!unzip -q output.zip\n",
    "!mkdir dataset\n",
    "# !wget -q https://github.com/chaosarium/3D-GANCA/blob/master/dataset/filtered_houses_stats.pkl4 -O dataset/filtered_houses_stats.pkl4\n",
    "# !wget -q https://github.com/chaosarium/3D-GANCA/blob/master/dataset/filtered_houses_stats.pkl -O dataset/filtered_houses_stats.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OXAbk29ubUCP",
    "outputId": "f295e52e-d03b-4404-fe6a-be7dd410ae0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip --quiet install torchsummaryX loguru einops pytorch_lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G0AuuMetY4xh",
    "outputId": "7d4500f4-10c3-48bb-931d-6ab0d43dd1d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "CUDNN VERSION: 8200\n",
      "Number CUDA Devices: 1\n",
      "CUDA Device Name: NVIDIA A40\n",
      "CUDA Device Total Memory [GB]: 47.85078272\n"
     ]
    }
   ],
   "source": [
    "# import stuff\n",
    "\n",
    "import data_helper\n",
    "from data_helper import GANCA3DDataModule\n",
    "from models import VoxelPerceptionNet, VoxelUpdateNet, VoxelNCAModel, VoxelDiscriminator\n",
    "import utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "from torchsummaryX import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning import Trainer\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from loguru import logger as gurulogger\n",
    "gurulogger.remove()\n",
    "gurulogger.add(sys.stdout, colorize=True, format=\"<blue>{time}</blue> <level>{message}</level>\")\n",
    "gurulogger.level(\"INFO\", color=\"<red><bold>\")\n",
    "\n",
    "import os\n",
    "from einops import rearrange\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "BLOCK2VEC_OUT_PATH = 'output/block2vec saves/block2vec 64 dim locked air/'\n",
    "NUM_WORKERS = int(os.cpu_count() / 2)\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "    print('CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ulC-44_aY4xk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding, mcid2block, block2embeddingidx, embeddingidx2block = utils.get_embedding_info(BLOCK2VEC_OUT_PATH)\n",
    "air_embedding = embedding(torch.tensor(block2embeddingidx['minecraft:air']))\n",
    "air_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MM GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eELhjPZ1Y4xn"
   },
   "outputs": [],
   "source": [
    "class GANCA_MMGAN(pl.LightningModule):\n",
    "\n",
    "    def __init__(self,\n",
    "            lr = 2e-4,\n",
    "            beta1 = 0.9,\n",
    "            beta2 = 0.999,\n",
    "            batch_size = 16,\n",
    "            num_embedding_channels = 64,\n",
    "            num_hidden_channels = 63,\n",
    "            update_net_channel_dims = [32, 32],\n",
    "            embedding: torch.nn.Embedding = None,\n",
    "            step_range = [16, 20],\n",
    "        ):\n",
    "        \n",
    "        super().__init__()\n",
    "        # call this to save args to the checkpoint\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.batch_size = batch_size\n",
    "        self.num_embedding_channels = num_embedding_channels\n",
    "        self.num_hidden_channels = num_hidden_channels\n",
    "        self.update_net_channel_dims = update_net_channel_dims\n",
    "        # the channels will be like [alpha, embeddings ... , hiddens ...]\n",
    "        self.num_channels = 1 + self.num_embedding_channels + self.num_hidden_channels\n",
    "        self.world_size = (32,32,32)\n",
    "        self.embedding = embedding\n",
    "        self.embedding.weight.requires_grad=False # freeze embeddings\n",
    "        self.step_range = step_range\n",
    "        \n",
    "        self.generator = VoxelNCAModel(\n",
    "            alpha_living_threshold = 0.1,\n",
    "            cell_fire_rate = 0.5,\n",
    "            num_perceptions = 3,\n",
    "            perception_requires_grad = True,\n",
    "            num_embedding_channels = self.num_embedding_channels,\n",
    "            num_hidden_channels = self.num_hidden_channels,\n",
    "            normal_std = 0.0002,\n",
    "            use_normal_init = True,\n",
    "            zero_bias = True,\n",
    "            update_net_channel_dims = self.update_net_channel_dims,\n",
    "        )\n",
    "        self.discriminator = VoxelDiscriminator(\n",
    "            num_in_channels = self.num_embedding_channels, \n",
    "            use_sigmoid=True,\n",
    "        )\n",
    "        \n",
    "        # generate some random seeds (N, channels, x, y, z)\n",
    "        self.validation_noise = self.make_seed_states(16)\n",
    "        \n",
    "    def make_seed_states(self, batch_size):\n",
    "        return utils.make_seed_state(\n",
    "            batch_size = batch_size,\n",
    "            num_channels = self.num_channels, \n",
    "            alpha_channel_index = 0,\n",
    "            seed_dim = (4, 4, 4), \n",
    "            world_size = self.world_size,\n",
    "        )\n",
    "    \n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        \n",
    "        num_steps = random.randint(*self.step_range)\n",
    "            \n",
    "        real_houses = batch\n",
    "        type_holder = batch[0,0,0,0].to(torch.float) # this is a dummy type for creating labels\n",
    "        size_this_batch = real_houses.shape[0]\n",
    "                \n",
    "        # make noise\n",
    "        \n",
    "        seed_states = self.make_seed_states(size_this_batch).type_as(type_holder) # same batch size as those coming in\n",
    "            \n",
    "        # train generator\n",
    "        if optimizer_idx == 0:\n",
    "            \n",
    "            # generate images\n",
    "            fake_houses_states = self.generator.forward(seed_states, steps=num_steps)\n",
    "                        \n",
    "            # create ground truth result (all fake results) we want D to say the generated ones are real so they are all 1s\n",
    "            real_labels = utils.make_real_labels(size_this_batch).type_as(type_holder)\n",
    "            \n",
    "            # now get the embedding parts out of the fake states\n",
    "            fake_houses = fake_houses_states[:, 1:self.num_embedding_channels+1, :, :, :]\n",
    "            \n",
    "            # see what discriminator thinks\n",
    "            fake_predictions = self.discriminator.forward(fake_houses)\n",
    "            \n",
    "            # calculate loss\n",
    "            g_loss = F.binary_cross_entropy(fake_predictions, real_labels) # y_hat, y  \n",
    "                                    \n",
    "            self.log(\"g_loss\", g_loss.detach(), prog_bar=True, logger=True)\n",
    "\n",
    "            return g_loss\n",
    "        \n",
    "        if optimizer_idx == 1:\n",
    "            \n",
    "            # get embeddings for the real house\n",
    "            real_houses = utils.examples2embedding(real_houses, self.embedding)\n",
    "            \n",
    "            # pass in real image to D and try to make it predict all 1s\n",
    "            real_targets = utils.make_real_labels(size_this_batch).type_as(type_holder)\n",
    "            real_predictions = self.discriminator.forward(real_houses)\n",
    "            real_loss = F.binary_cross_entropy(real_predictions, real_targets)\n",
    "            # TODO fix accuracy formula\n",
    "            real_acc = torch.mean(real_predictions).item() # the average prediction. The closer to 1 the more accurate\n",
    "            \n",
    "            # meanwhile, we also want D to be able to tell that outputs from G are all fake\n",
    "            fake_targets = utils.make_fake_labels(size_this_batch).type_as(type_holder)\n",
    "            fake_houses_states = self.generator.forward(seed_states, steps=num_steps).detach() # detach so that gradients don't pass back into generator\n",
    "            fake_houses = fake_houses_states[:, 1:self.num_embedding_channels+1, :, :, :] # extract the embedding parts\n",
    "            fake_predictions = self.discriminator.forward(fake_houses)\n",
    "            fake_loss = F.binary_cross_entropy(fake_predictions, fake_targets)\n",
    "            # TODO fix accuracy formula\n",
    "            fake_acc = 1 - torch.mean(fake_predictions).item() # the 1 - average prediction. The closer to 1 the more accurate\n",
    "                        \n",
    "            # discriminator loss is the average of the two losses\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            avg_acc = (real_acc + fake_acc) / 2\n",
    "                    \n",
    "            self.log(\"fake_loss\", fake_loss.detach(), prog_bar=False, logger=True)\n",
    "            self.log(\"real_loss\", real_loss.detach(), prog_bar=False, logger=True)\n",
    "            self.log(\"d_loss\", d_loss.detach(), prog_bar=True, logger=True)\n",
    "            self.log(\"real_acc\", real_acc, prog_bar=False, logger=True)\n",
    "            self.log(\"fake_acc\", fake_acc, prog_bar=False, logger=True)\n",
    "            self.log(\"avg_acc\", avg_acc, prog_bar=True, logger=True)\n",
    "\n",
    "            return d_loss\n",
    "\n",
    "    def configure_optimizers(self,):\n",
    "        # define pytorch optimizers here. return [list of optimizers], [list of LR schedulers]\n",
    "        g_optimizer = torch.optim.Adam(self.generator.parameters(), lr=self.lr, betas=(self.beta1, self.beta2))\n",
    "        d_optimizer = torch.optim.Adam(self.discriminator.parameters(), lr=self.lr, betas=(self.beta1, self.beta2))\n",
    "        return [g_optimizer, d_optimizer], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lonFxlJKY4xq"
   },
   "outputs": [],
   "source": [
    "model = GANCA_MMGAN(\n",
    "    lr = 2e-4,\n",
    "    beta1 = 0.9,\n",
    "    beta2 = 0.999,\n",
    "    batch_size = 8,\n",
    "    num_embedding_channels = 64,\n",
    "    num_hidden_channels = 63,\n",
    "    update_net_channel_dims = [16, 16],\n",
    "    embedding = embedding,\n",
    "    step_range = [16, 20],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "2bdc0941b3dc499496679c7183fbff37",
      "5ae9d82c8a094e79920bb1724cfe53e8",
      "96facbd6da40424c93f074bafcb76bbe",
      "9ecea295f69c405c93af3df43b354f75",
      "9a928ccf02ae4c668bfc2be196f31376",
      "42edc229ae79434388cea378717a9aaf",
      "a65f1f8a486f47419cab33d55d86d7f9",
      "67c0303d8a574ebe9e5b35036297b8d5",
      "9060020c253a4429bfadca4b37cb5f2c",
      "e369d4e56d89406f83db778df71ffe05",
      "c6fd5703ce2743948c5decccee2d602b"
     ]
    },
    "id": "9HO0hndNY4xr",
    "outputId": "6324c09c-c795-4879-e4fa-0fa57a25e588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:175: LightningDeprecationWarning: DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\"DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bdc0941b3dc499496679c7183fbff37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1977 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 1977 houses\n",
      "Turning MC id into embedding idx. This could take up to a minute.\n"
     ]
    }
   ],
   "source": [
    "dm = GANCA3DDataModule(batch_size=8, num_workers=1, mcid2block = mcid2block, block2embeddingid = block2embeddingidx, debug=False)\n",
    "dm.prepare_data()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1CR1dFG7Y4xr",
    "outputId": "8b398d80-b248-4be9-a5ca-3c034df5637b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "logger = pl.loggers.TensorBoardLogger(save_dir='lightning_logs', name='GANCA', default_hp_metric=False)\n",
    "trainer = Trainer(gpus=1, max_epochs=1, fast_dev_run=False, log_every_n_steps=1, logger=logger, profiler=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434,
     "referenced_widgets": [
      "ee702aff0c59434fa13204508cb5d22d",
      "c3805b1dda574f99a51de0c5d55b9680",
      "a5a13ea11c644321af52864783858480",
      "d609d2a11ddc48d2b5bfb05303d090d1",
      "726aa9cc89954c079c5f95faffbd4ac9",
      "dbf6830427734779b2205e75544b5d02",
      "d7c23ef46d9e4b8ab6c4086a11d23d1c",
      "c6254117a2a34d21b9880429680304b8",
      "906bb93fea954f17aec435cdbb592bee",
      "9eb0c4b9d0884e53badf26ab9bcab9c0",
      "dba04c61834b49b79f7bfd2b669a99ba"
     ]
    },
    "id": "QdN43RM2Y4xs",
    "outputId": "d8dcb443-6a68-4de7-b08b-018b8f06dd24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:120: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:470: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Missing logger folder: lightning_logs/GANCA\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | embedding     | Embedding          | 14.0 K\n",
      "1 | generator     | VoxelNCAModel      | 18.8 K\n",
      "2 | discriminator | VoxelDiscriminator | 11.3 M\n",
      "-----------------------------------------------------\n",
      "11.3 M    Trainable params\n",
      "14.0 K    Non-trainable params\n",
      "11.3 M    Total params\n",
      "45.244    Total estimated model params size (MB)\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee702aff0c59434fa13204508cb5d22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANCA_WGAN(pl.LightningModule):\n",
    "\n",
    "    def __init__(self,\n",
    "            lr = 2e-4,\n",
    "            # beta1 = 0.9,\n",
    "            # beta2 = 0.999,\n",
    "            weight_clip = 0.01, # glipping gradient in WGAN\n",
    "            batch_size = 16,\n",
    "            num_embedding_channels = 64,\n",
    "            num_hidden_channels = 63,\n",
    "            update_net_channel_dims = [32, 32],\n",
    "            embedding: torch.nn.Embedding = None,\n",
    "            step_range = [16, 20],\n",
    "        ):\n",
    "        \n",
    "        super().__init__()\n",
    "        # call this to save args to the checkpoint\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.weight_clip = weight_clip\n",
    "        # self.beta1 = beta1\n",
    "        # self.beta2 = beta2\n",
    "        self.batch_size = batch_size\n",
    "        self.num_embedding_channels = num_embedding_channels\n",
    "        self.num_hidden_channels = num_hidden_channels\n",
    "        self.update_net_channel_dims = update_net_channel_dims\n",
    "        # the channels will be like [alpha, embeddings ... , hiddens ...]\n",
    "        self.num_channels = 1 + self.num_embedding_channels + self.num_hidden_channels\n",
    "        self.world_size = (32,32,32)\n",
    "        self.seed_size = (2,2,2)\n",
    "        self.embedding = embedding\n",
    "        self.embedding.weight.requires_grad=False # freeze embeddings\n",
    "        self.step_range = step_range\n",
    "        \n",
    "        self.generator = VoxelNCAModel(\n",
    "            alpha_living_threshold = 0.1,\n",
    "            cell_fire_rate = 0.5,\n",
    "            num_perceptions = 3,\n",
    "            perception_requires_grad = True,\n",
    "            num_embedding_channels = self.num_embedding_channels,\n",
    "            num_hidden_channels = self.num_hidden_channels,\n",
    "            normal_std = 0.0002,\n",
    "            use_normal_init = True,\n",
    "            zero_bias = True,\n",
    "            update_net_channel_dims = self.update_net_channel_dims,\n",
    "        )\n",
    "        self.discriminator = VoxelDiscriminator(\n",
    "            num_in_channels = self.num_embedding_channels, \n",
    "            use_sigmoid=False,\n",
    "        )\n",
    "        \n",
    "        # generate some random seeds (N, channels, x, y, z)\n",
    "        self.validation_noise = self.make_seed_states(16)\n",
    "        \n",
    "    def make_seed_states(self, batch_size):\n",
    "        return utils.make_seed_state(\n",
    "            batch_size = batch_size,\n",
    "            num_channels = self.num_channels, \n",
    "            alpha_channel_index = 0,\n",
    "            seed_dim = self.seed_size, \n",
    "            world_size = self.world_size,\n",
    "        )\n",
    "    \n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "                \n",
    "        num_steps = random.randint(*self.step_range)\n",
    "\n",
    "        real_houses_indices = batch\n",
    "        type_holder = batch[0,0,0,0].to(torch.float) # this is a dummy type for creating labels\n",
    "        size_this_batch = real_houses_indices.shape[0]\n",
    "                \n",
    "        # make noise\n",
    "        seed_states = self.make_seed_states(size_this_batch).type_as(type_holder) # same batch size as those coming in\n",
    "            \n",
    "        # train generator\n",
    "        if optimizer_idx == 0:\n",
    "            \n",
    "            # generate fake houses and get the embedding parts out of it\n",
    "            fake_houses_states = self.generator.forward(seed_states, steps=num_steps)\n",
    "            fake_houses = fake_houses_states[:, 1:self.num_embedding_channels+1, :, :, :]\n",
    "            \n",
    "            # train gen\n",
    "            g_loss = self.train_generator(fake_houses)              \n",
    "            self.log(\"g_loss\", g_loss.detach(), prog_bar=True, logger=True)\n",
    "            return g_loss\n",
    "        \n",
    "        if optimizer_idx == 1:\n",
    "                        \n",
    "            # get embeddings for the real house\n",
    "            real_houses = utils.examples2embedding(real_houses_indices, self.embedding)\n",
    "\n",
    "            # generate fake houses\n",
    "            fake_houses_states = self.generator.forward(seed_states, steps=num_steps).detach() # detach so that gradients don't pass back into generator\n",
    "            fake_houses = fake_houses_states[:, 1:self.num_embedding_channels+1, :, :, :] # extract the embedding parts\n",
    "            \n",
    "            # train D\n",
    "            d_loss, real_loss, fake_loss = self.train_discriminator(real_houses, fake_houses)\n",
    "\n",
    "            # logging\n",
    "            self.log(\"fake_loss\", fake_loss.detach(), prog_bar=False, logger=True)\n",
    "            self.log(\"real_loss\", real_loss.detach(), prog_bar=False, logger=True)\n",
    "            self.log(\"d_loss\", d_loss.detach(), prog_bar=True, logger=True)\n",
    "            # TODO implement on acc calculations\n",
    "            # self.log(\"real_acc\", real_acc, prog_bar=False, logger=True)\n",
    "            # self.log(\"fake_acc\", fake_acc, prog_bar=False, logger=True)\n",
    "            # self.log(\"avg_acc\", avg_acc, prog_bar=True, logger=True)\n",
    "\n",
    "            return d_loss\n",
    "\n",
    "    def train_discriminator(self, real_houses, fake_houses):\n",
    "        \n",
    "        # making sure that real and fake have same shape\n",
    "        assert real_houses.shape == fake_houses.shape\n",
    "\n",
    "        # make predictions on real houses and see what D thinks\n",
    "        real_predictions = self.discriminator.forward(real_houses)\n",
    "        # For WGAN, we no longer use binary cross entropy. There is no target here.\n",
    "        real_loss = - torch.mean(real_predictions) # maximising is the same as minimising the negative\n",
    "        \n",
    "        # see what D thinks on fake houses\n",
    "        fake_predictions = self.discriminator.forward(real_houses)\n",
    "        # once again, not BCE here\n",
    "        fake_loss = torch.mean(fake_predictions)\n",
    "        \n",
    "        # make loss the sum\n",
    "        d_loss = real_loss + fake_loss\n",
    "        \n",
    "        # clamp parameters\n",
    "        for param in self.discriminator.parameters():\n",
    "            param.data.clamp_(-self.weight_clip, self.weight_clip)\n",
    "        \n",
    "        return d_loss, real_loss, fake_loss\n",
    "    \n",
    "    def train_generator(self, fake_houses):\n",
    "        \n",
    "        # see what D thinks \n",
    "        fake_predictions = self.discriminator.forward(fake_houses)\n",
    "        \n",
    "        # calc loss. We want to maximise the prediction for this one (only doing so with G's parameters)\n",
    "        g_loss = -torch.mean(fake_predictions)\n",
    "        \n",
    "        return g_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        n_critic = 5\n",
    "        \n",
    "        # for WGAN, use RMSprop\n",
    "        g_optimizer = torch.optim.RMSprop(self.generator.parameters(), lr=self.lr)\n",
    "        d_optimizer = torch.optim.RMSprop(self.discriminator.parameters(), lr=self.lr)\n",
    "        \n",
    "        return (\n",
    "            {\"optimizer\": g_optimizer, \"frequency\": 1},\n",
    "            {\"optimizer\": d_optimizer, \"frequency\": n_critic}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GANCA_WGAN(\n",
    "    lr = 2e-4,\n",
    "    weight_clip = 0.01,\n",
    "    batch_size = 2,\n",
    "    num_embedding_channels = 64,\n",
    "    num_hidden_channels = 63,\n",
    "    update_net_channel_dims = [8, 8],\n",
    "    embedding = embedding,\n",
    "    step_range = [1, 3],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "2bdc0941b3dc499496679c7183fbff37",
      "5ae9d82c8a094e79920bb1724cfe53e8",
      "96facbd6da40424c93f074bafcb76bbe",
      "9ecea295f69c405c93af3df43b354f75",
      "9a928ccf02ae4c668bfc2be196f31376",
      "42edc229ae79434388cea378717a9aaf",
      "a65f1f8a486f47419cab33d55d86d7f9",
      "67c0303d8a574ebe9e5b35036297b8d5",
      "9060020c253a4429bfadca4b37cb5f2c",
      "e369d4e56d89406f83db778df71ffe05",
      "c6fd5703ce2743948c5decccee2d602b"
     ]
    },
    "id": "9HO0hndNY4xr",
    "outputId": "6324c09c-c795-4879-e4fa-0fa57a25e588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:175: LightningDeprecationWarning: DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\"DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701ead6808cd4f08a64380af92d5350d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1977 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 1977 houses\n",
      "Turning MC id into embedding idx. This could take up to a minute.\n"
     ]
    }
   ],
   "source": [
    "dm = GANCA3DDataModule(batch_size=2, num_workers=1, mcid2block = mcid2block, block2embeddingid = block2embeddingidx, debug=True)\n",
    "dm.prepare_data()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1CR1dFG7Y4xr",
    "outputId": "8b398d80-b248-4be9-a5ca-3c034df5637b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "logger = pl.loggers.TensorBoardLogger(save_dir='lightning_logs', name='GANCA', default_hp_metric=False)\n",
    "trainer = Trainer(gpus=0, max_epochs=2, fast_dev_run=False, log_every_n_steps=1, logger=logger, profiler=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434,
     "referenced_widgets": [
      "ee702aff0c59434fa13204508cb5d22d",
      "c3805b1dda574f99a51de0c5d55b9680",
      "a5a13ea11c644321af52864783858480",
      "d609d2a11ddc48d2b5bfb05303d090d1",
      "726aa9cc89954c079c5f95faffbd4ac9",
      "dbf6830427734779b2205e75544b5d02",
      "d7c23ef46d9e4b8ab6c4086a11d23d1c",
      "c6254117a2a34d21b9880429680304b8",
      "906bb93fea954f17aec435cdbb592bee",
      "9eb0c4b9d0884e53badf26ab9bcab9c0",
      "dba04c61834b49b79f7bfd2b669a99ba"
     ]
    },
    "id": "QdN43RM2Y4xs",
    "outputId": "d8dcb443-6a68-4de7-b08b-018b8f06dd24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:120: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n",
      "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | embedding     | Embedding          | 14.0 K\n",
      "1 | generator     | VoxelNCAModel      | 14.5 K\n",
      "2 | discriminator | VoxelDiscriminator | 11.3 M\n",
      "-----------------------------------------------------\n",
      "11.3 M    Trainable params\n",
      "14.0 K    Non-trainable params\n",
      "11.3 M    Total params\n",
      "45.227    Total estimated model params size (MB)\n",
      "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/8 [00:00<?, ?it/s] \u001b[34m2022-03-03T12:01:51.444992+0800\u001b[0m \u001b[31m\u001b[1mtraining step with optimizer_idx 0\u001b[0m\n",
      "\u001b[34m2022-03-03T12:01:51.450620+0800\u001b[0m \u001b[31m\u001b[1mtraining G\u001b[0m\n",
      "Epoch 0:  12%|█▎        | 1/8 [00:03<00:25,  3.60s/it, loss=-0.0409, v_num=4, g_loss=-.0409]\u001b[34m2022-03-03T12:01:52.942144+0800\u001b[0m \u001b[31m\u001b[1mtraining step with optimizer_idx 1\u001b[0m\n",
      "\u001b[34m2022-03-03T12:01:52.943449+0800\u001b[0m \u001b[31m\u001b[1mtraining D\u001b[0m\n",
      "Epoch 0:  25%|██▌       | 2/8 [00:04<00:13,  2.31s/it, loss=-0.0205, v_num=4, g_loss=-.0409, d_loss=0.000]\u001b[34m2022-03-03T12:01:53.832096+0800\u001b[0m \u001b[31m\u001b[1mtraining step with optimizer_idx 1\u001b[0m\n",
      "\u001b[34m2022-03-03T12:01:53.834149+0800\u001b[0m \u001b[31m\u001b[1mtraining D\u001b[0m\n",
      "Epoch 0:  38%|███▊      | 3/8 [00:05<00:09,  1.96s/it, loss=-0.0136, v_num=4, g_loss=-.0409, d_loss=0.000]\u001b[34m2022-03-03T12:01:55.073479+0800\u001b[0m \u001b[31m\u001b[1mtraining step with optimizer_idx 1\u001b[0m\n",
      "\u001b[34m2022-03-03T12:01:55.075047+0800\u001b[0m \u001b[31m\u001b[1mtraining D\u001b[0m\n",
      "Epoch 0:  50%|█████     | 4/8 [00:06<00:06,  1.72s/it, loss=-0.0102, v_num=4, g_loss=-.0409, d_loss=0.000]\u001b[34m2022-03-03T12:01:56.070933+0800\u001b[0m \u001b[31m\u001b[1mtraining step with optimizer_idx 1\u001b[0m\n",
      "\u001b[34m2022-03-03T12:01:56.072363+0800\u001b[0m \u001b[31m\u001b[1mtraining D\u001b[0m\n",
      "Epoch 0:  62%|██████▎   | 5/8 [00:07<00:04,  1.54s/it, loss=-0.00818, v_num=4, g_loss=-.0409, d_loss=0.000]\u001b[34m2022-03-03T12:01:56.897662+0800\u001b[0m \u001b[31m\u001b[1mtraining step with optimizer_idx 1\u001b[0m\n",
      "\u001b[34m2022-03-03T12:01:56.898886+0800\u001b[0m \u001b[31m\u001b[1mtraining D\u001b[0m\n",
      "Epoch 0:  75%|███████▌  | 6/8 [00:08<00:02,  1.47s/it, loss=-0.00682, v_num=4, g_loss=-.0409, d_loss=0.000]\u001b[34m2022-03-03T12:01:58.023819+0800\u001b[0m \u001b[31m\u001b[1mtraining step with optimizer_idx 0\u001b[0m\n",
      "\u001b[34m2022-03-03T12:01:58.025562+0800\u001b[0m \u001b[31m\u001b[1mtraining G\u001b[0m\n",
      "Epoch 0:  88%|████████▊ | 7/8 [00:10<00:01,  1.53s/it, loss=-0.00584, v_num=4, g_loss=3.4e-5, d_loss=0.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANCA_WGANGP(pl.LightningModule):\n",
    "\n",
    "    def __init__(self,\n",
    "            lr = 0.0001,\n",
    "            beta1 = 0,\n",
    "            beta2 = 0.9,\n",
    "            n_gen = 1,\n",
    "            n_critic = 5,\n",
    "            lambda_gp = 10,\n",
    "            weight_clip = 0.01,\n",
    "            num_embedding_channels = 64,\n",
    "            num_hidden_channels = 63,\n",
    "            update_net_channel_dims = [32, 32],\n",
    "            embedding: torch.nn.Embedding = None,\n",
    "            step_range = [16, 20],\n",
    "        ):\n",
    "        \n",
    "        super().__init__()\n",
    "        # call this to save args to the checkpoint\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.weight_clip = weight_clip\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.n_gen = n_gen\n",
    "        self.n_critic = n_critic\n",
    "        self.lambda_gp = lambda_gp\n",
    "        self.num_embedding_channels = num_embedding_channels\n",
    "        self.num_hidden_channels = num_hidden_channels\n",
    "        self.update_net_channel_dims = update_net_channel_dims\n",
    "        # the channels will be like [alpha, embeddings ... , hiddens ...]\n",
    "        self.num_channels = 1 + self.num_embedding_channels + self.num_hidden_channels\n",
    "        self.world_size = (32,32,32)\n",
    "        self.seed_size = (2,2,2)\n",
    "        self.embedding = embedding\n",
    "        self.embedding.weight.requires_grad=False # freeze embeddings\n",
    "        self.step_range = step_range\n",
    "        \n",
    "        self.generator = VoxelNCAModel(\n",
    "            alpha_living_threshold = 0.1,\n",
    "            cell_fire_rate = 0.5,\n",
    "            num_perceptions = 3,\n",
    "            perception_requires_grad = True,\n",
    "            num_embedding_channels = self.num_embedding_channels,\n",
    "            num_hidden_channels = self.num_hidden_channels,\n",
    "            normal_std = 0.0002,\n",
    "            use_normal_init = True,\n",
    "            zero_bias = True,\n",
    "            update_net_channel_dims = self.update_net_channel_dims,\n",
    "        )\n",
    "        self.discriminator = VoxelDiscriminator(\n",
    "            num_in_channels = self.num_embedding_channels, \n",
    "            use_sigmoid=False,\n",
    "        )\n",
    "        \n",
    "        # generate some random seeds (N, channels, x, y, z)\n",
    "        self.validation_noise = self.make_seed_states(16)\n",
    "        \n",
    "    def make_seed_states(self, batch_size):\n",
    "        return utils.make_seed_state(\n",
    "            batch_size = batch_size,\n",
    "            num_channels = self.num_channels, \n",
    "            alpha_channel_index = 0,\n",
    "            seed_dim = self.seed_size, \n",
    "            world_size = self.world_size,\n",
    "        )\n",
    "    \n",
    "    def compute_gradient_penalty(self, real_samples, fake_samples):\n",
    "        # gurulogger.info(f\"compute gradient panelty\")\n",
    "        # gurulogger.info(f\"real samples shape{real_samples.shape}; fake samples shape {fake_samples.shape}\")\n",
    "        \n",
    "        # Random weight term for interpolation between real and fake samples. We get a tensor of shape (N, 1, 1, 1, 1)\n",
    "        alpha = torch.Tensor(np.random.random((real_samples.size(0), 1, 1, 1, 1))).to(self.device)\n",
    "        # Get random interpolation between real and fake samples\n",
    "        interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "        interpolates = interpolates.to(self.device)\n",
    "        # calc predictions for interpolated samples\n",
    "        interpolates_predictions = self.discriminator.forward(interpolates)\n",
    "        fake = torch.Tensor(real_samples.shape[0], 1).fill_(1.0).to(self.device)\n",
    "        # Get gradient w.r.t. interpolates\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=interpolates_predictions,\n",
    "            inputs=interpolates,\n",
    "            grad_outputs=fake,\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True,\n",
    "        )[0]\n",
    "        \n",
    "        # gurulogger.info(f\"gradients shape {gradients.shape}\")\n",
    "        gradients = gradients.reshape(gradients.size(0), -1).to(self.device)\n",
    "        # gurulogger.info(f\"gradients shape after view {gradients.shape}\")\n",
    "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "        return gradient_penalty\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        \n",
    "        num_steps = random.randint(*self.step_range)\n",
    "\n",
    "        real_houses_indices = batch\n",
    "        type_holder = batch[0,0,0,0].to(torch.float) # this is a dummy type for creating labels\n",
    "        size_this_batch = real_houses_indices.shape[0]\n",
    "                \n",
    "        # make noise\n",
    "        seed_states = self.make_seed_states(size_this_batch).type_as(type_holder) # same batch size as those coming in\n",
    "            \n",
    "        # train generator\n",
    "        if optimizer_idx == 0:\n",
    "\n",
    "            # generate fake houses and get the embedding parts out of it\n",
    "            fake_houses_states = self.generator.forward(seed_states, steps=num_steps)\n",
    "            fake_houses = fake_houses_states[:, 1:self.num_embedding_channels+1, :, :, :]\n",
    "            \n",
    "            # train gen\n",
    "            g_loss = self.train_generator(fake_houses)  \n",
    "                        \n",
    "            self.log(\"g_loss\", g_loss.detach(), prog_bar=True, logger=True)\n",
    "            return g_loss\n",
    "        \n",
    "        if optimizer_idx == 1:\n",
    "            \n",
    "            # get embeddings for the real house\n",
    "            real_houses = utils.examples2embedding(real_houses_indices, self.embedding)\n",
    "\n",
    "            # generate fake houses\n",
    "            fake_houses_states = self.generator.forward(seed_states, steps=num_steps).detach() # detach so that gradients don't pass back into generator\n",
    "            fake_houses = fake_houses_states[:, 1:self.num_embedding_channels+1, :, :, :] # extract the embedding parts\n",
    "            \n",
    "            # train D\n",
    "            d_loss = self.train_discriminator(real_houses, fake_houses)\n",
    "\n",
    "            # logging\n",
    "            self.log(\"d_loss\", d_loss.detach(), prog_bar=True, logger=True)\n",
    "            return d_loss\n",
    "\n",
    "    def train_discriminator(self, real_houses, fake_houses):\n",
    "        assert real_houses.shape == fake_houses.shape\n",
    "\n",
    "        real_predictions = self.discriminator.forward(real_houses)\n",
    "        fake_predictions = self.discriminator.forward(fake_houses)\n",
    "        self.log(\"real_validity\", torch.mean(real_predictions).detach(), prog_bar=True, logger=True)\n",
    "        self.log(\"fake_validity\", torch.mean(fake_predictions).detach(), prog_bar=True, logger=True)\n",
    "        \n",
    "        gradient_penalty = self.compute_gradient_penalty(real_houses.data, fake_houses.data)\n",
    "                \n",
    "        d_loss = -torch.mean(real_predictions) + torch.mean(fake_predictions) + self.lambda_gp * gradient_penalty\n",
    "                \n",
    "        return d_loss\n",
    "    \n",
    "    def train_generator(self, fake_houses):\n",
    "        # see what D thinks \n",
    "        fake_predictions = self.discriminator.forward(fake_houses)\n",
    "        \n",
    "        # calc loss. We want to maximise the prediction for this one (only doing so with G's parameters)\n",
    "        g_loss = -torch.mean(fake_predictions)\n",
    "        \n",
    "        return g_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        g_optimizer = torch.optim.Adam(self.generator.parameters(), lr=self.lr, betas=(self.beta1, self.beta2))\n",
    "        d_optimizer = torch.optim.Adam(self.discriminator.parameters(), lr=self.lr, betas=(self.beta1, self.beta2))\n",
    "        \n",
    "        return [\n",
    "            {\"optimizer\": g_optimizer, \"frequency\": self.n_gen},\n",
    "            {\"optimizer\": d_optimizer, \"frequency\": self.n_critic},\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GANCA_WGANGP(\n",
    "    lr = 0.0001,\n",
    "    beta1 = 0,\n",
    "    beta2 = 0.9,\n",
    "    n_gen = 5,\n",
    "    n_critic = 2,\n",
    "    lambda_gp = 10,\n",
    "    weight_clip = 0.01,\n",
    "    num_embedding_channels = 64,\n",
    "    num_hidden_channels = 63,\n",
    "    update_net_channel_dims = [32, 32],\n",
    "    embedding = embedding,\n",
    "    step_range = [32, 36],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "2bdc0941b3dc499496679c7183fbff37",
      "5ae9d82c8a094e79920bb1724cfe53e8",
      "96facbd6da40424c93f074bafcb76bbe",
      "9ecea295f69c405c93af3df43b354f75",
      "9a928ccf02ae4c668bfc2be196f31376",
      "42edc229ae79434388cea378717a9aaf",
      "a65f1f8a486f47419cab33d55d86d7f9",
      "67c0303d8a574ebe9e5b35036297b8d5",
      "9060020c253a4429bfadca4b37cb5f2c",
      "e369d4e56d89406f83db778df71ffe05",
      "c6fd5703ce2743948c5decccee2d602b"
     ]
    },
    "id": "9HO0hndNY4xr",
    "outputId": "6324c09c-c795-4879-e4fa-0fa57a25e588",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:175: LightningDeprecationWarning: DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\"DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7177cf734b2948388ca10b89f6779db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1977 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 1977 houses\n",
      "Turning MC id into embedding idx. This could take up to a minute.\n",
      "Done with that.\n"
     ]
    }
   ],
   "source": [
    "dm = GANCA3DDataModule(batch_size=8, num_workers=NUM_WORKERS, mcid2block = mcid2block, block2embeddingid = block2embeddingidx, debug=False)\n",
    "dm.prepare_data()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1CR1dFG7Y4xr",
    "outputId": "8b398d80-b248-4be9-a5ca-3c034df5637b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "logger = pl.loggers.TensorBoardLogger(save_dir='../tf-logs', name='GANCA', default_hp_metric=False)\n",
    "trainer = Trainer(gpus=1, max_epochs=8, fast_dev_run=False, log_every_n_steps=1, logger=logger, profiler=None, precision=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434,
     "referenced_widgets": [
      "ee702aff0c59434fa13204508cb5d22d",
      "c3805b1dda574f99a51de0c5d55b9680",
      "a5a13ea11c644321af52864783858480",
      "d609d2a11ddc48d2b5bfb05303d090d1",
      "726aa9cc89954c079c5f95faffbd4ac9",
      "dbf6830427734779b2205e75544b5d02",
      "d7c23ef46d9e4b8ab6c4086a11d23d1c",
      "c6254117a2a34d21b9880429680304b8",
      "906bb93fea954f17aec435cdbb592bee",
      "9eb0c4b9d0884e53badf26ab9bcab9c0",
      "dba04c61834b49b79f7bfd2b669a99ba"
     ]
    },
    "id": "QdN43RM2Y4xs",
    "outputId": "d8dcb443-6a68-4de7-b08b-018b8f06dd24",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:120: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n",
      "/root/miniconda3/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | embedding     | Embedding          | 14.0 K\n",
      "1 | generator     | VoxelNCAModel      | 27.8 K\n",
      "2 | discriminator | VoxelDiscriminator | 11.3 M\n",
      "-----------------------------------------------------\n",
      "11.3 M    Trainable params\n",
      "14.0 K    Non-trainable params\n",
      "11.3 M    Total params\n",
      "45.280    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d383cacc764c0f9e9ddaca365c271f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Copy of GANCA train.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "0228fee4d25496bb422a7e0c363e636da60e8258e4b70dda8036e2defd0af2d7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2bdc0941b3dc499496679c7183fbff37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_96facbd6da40424c93f074bafcb76bbe",
       "IPY_MODEL_9ecea295f69c405c93af3df43b354f75",
       "IPY_MODEL_9a928ccf02ae4c668bfc2be196f31376"
      ],
      "layout": "IPY_MODEL_5ae9d82c8a094e79920bb1724cfe53e8"
     }
    },
    "42edc229ae79434388cea378717a9aaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ae9d82c8a094e79920bb1724cfe53e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67c0303d8a574ebe9e5b35036297b8d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "726aa9cc89954c079c5f95faffbd4ac9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dba04c61834b49b79f7bfd2b669a99ba",
      "placeholder": "​",
      "style": "IPY_MODEL_9eb0c4b9d0884e53badf26ab9bcab9c0",
      "value": " 100/200 [03:06&lt;03:06,  1.86s/it, loss=5.49, v_num=0, g_loss=10.90, d_loss=3.16e-5, avg_acc=1.000]"
     }
    },
    "9060020c253a4429bfadca4b37cb5f2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "906bb93fea954f17aec435cdbb592bee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96facbd6da40424c93f074bafcb76bbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a65f1f8a486f47419cab33d55d86d7f9",
      "placeholder": "​",
      "style": "IPY_MODEL_42edc229ae79434388cea378717a9aaf",
      "value": "100%"
     }
    },
    "9a928ccf02ae4c668bfc2be196f31376": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6fd5703ce2743948c5decccee2d602b",
      "placeholder": "​",
      "style": "IPY_MODEL_e369d4e56d89406f83db778df71ffe05",
      "value": " 1977/1977 [00:01&lt;00:00, 1319.86it/s]"
     }
    },
    "9eb0c4b9d0884e53badf26ab9bcab9c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ecea295f69c405c93af3df43b354f75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9060020c253a4429bfadca4b37cb5f2c",
      "max": 1977,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67c0303d8a574ebe9e5b35036297b8d5",
      "value": 1977
     }
    },
    "a5a13ea11c644321af52864783858480": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7c23ef46d9e4b8ab6c4086a11d23d1c",
      "placeholder": "​",
      "style": "IPY_MODEL_dbf6830427734779b2205e75544b5d02",
      "value": "Epoch 0:  50%"
     }
    },
    "a65f1f8a486f47419cab33d55d86d7f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3805b1dda574f99a51de0c5d55b9680": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "c6254117a2a34d21b9880429680304b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c6fd5703ce2743948c5decccee2d602b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d609d2a11ddc48d2b5bfb05303d090d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_906bb93fea954f17aec435cdbb592bee",
      "max": 200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c6254117a2a34d21b9880429680304b8",
      "value": 100
     }
    },
    "d7c23ef46d9e4b8ab6c4086a11d23d1c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dba04c61834b49b79f7bfd2b669a99ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbf6830427734779b2205e75544b5d02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e369d4e56d89406f83db778df71ffe05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee702aff0c59434fa13204508cb5d22d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a5a13ea11c644321af52864783858480",
       "IPY_MODEL_d609d2a11ddc48d2b5bfb05303d090d1",
       "IPY_MODEL_726aa9cc89954c079c5f95faffbd4ac9"
      ],
      "layout": "IPY_MODEL_c3805b1dda574f99a51de0c5d55b9680"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
