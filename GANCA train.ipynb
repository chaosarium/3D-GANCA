{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training GANCA-3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# import stuff\n",
    "\n",
    "import data_helper\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from torchsummaryX import summary\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from einops import rearrange\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "BLOCK2VEC_OUT_PATH = 'output/block2vec saves/block2vec 64 dim/'\n",
    "NUM_WORKERS = int(os.cpu_count() / 2)\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "    print('CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding, mcid2block, block2embeddingidx, embeddingidx2block = utils.get_embedding_info(BLOCK2VEC_OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_helper import GANCA3DDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:175: LightningDeprecationWarning: DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\"DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\")\n"
     ]
    }
   ],
   "source": [
    "dm = GANCA3DDataModule(batch_size=16, num_workers=1, mcid2block = mcid2block, block2embeddingid = block2embeddingidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import VoxelPerceptionNet, VoxelUpdateNet, VoxelNCAModel, VoxelDiscriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "# %tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANCA(pl.LightningModule):\n",
    "\n",
    "    def __init__(self,\n",
    "            latent_dim = 64,\n",
    "            image_shape = (3,32,32),\n",
    "            lr = 2e-4,\n",
    "            batch_size = 128,\n",
    "            beta1 = 0.9,\n",
    "            beta2 = 0.999\n",
    "        ):\n",
    "        \n",
    "        super().__init__()\n",
    "        # call this to save args to the checkpoint\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.image_shape = image_shape\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        \n",
    "                \n",
    "        self.generator = VoxelNCAModel(\n",
    "            alpha_living_threshold = 0.1,\n",
    "            cell_fire_rate = 0.5,\n",
    "            num_perceptions = 3,\n",
    "            perception_requires_grad = True,\n",
    "            num_hidden_channels = 127,\n",
    "            normal_std = 0.0002,\n",
    "            use_normal_init = True,\n",
    "            zero_bias = True,\n",
    "            update_net_channel_dims = [32, 32]\n",
    "        )\n",
    "        self.discriminator = VoxelDiscriminator(\n",
    "            num_in_channels = 64, \n",
    "            use_sigmoid=True\n",
    "        )\n",
    "        \n",
    "        # generate 16 random latent space data for validation of shape latent_dim, 1, 1\n",
    "        self.validation_noise = torch.randn(16, self.latent_dim, 1, 1)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # the forward step here\n",
    "        # in comes the (N, latent_dim, 1, 1) noise\n",
    "        return self.generator(z)\n",
    "    \n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        # this is an added function for calculating loss!\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "            \n",
    "        images, _ = batch\n",
    "        \n",
    "        # make noise\n",
    "        \n",
    "        noise = torch.randn(images.size(0), self.latent_dim, 1, 1) # same batch size as those coming in\n",
    "        noise = noise.type_as(images) # ensuring it's on device\n",
    "            \n",
    "        # train generator\n",
    "        if optimizer_idx == 0:\n",
    "            \n",
    "            # generate images\n",
    "            fake_images = self.generator(noise)\n",
    "            \n",
    "            # log some sample image\n",
    "            grid = torchvision.utils.make_grid(fake_images.detach()[:6])\n",
    "            self.logger.experiment.add_image(\"generated_images\", grid, 0)\n",
    "            \n",
    "            # create ground truth result (all fake results) we want D to say the generated ones are real so they are all 1s\n",
    "            real_targets = torch.ones(fake_images.size(0), 1).type_as(images) # ensuring it's on device\n",
    "            \n",
    "            # see what discriminator thinks\n",
    "            fake_predictions = self.discriminator(fake_images)\n",
    "            \n",
    "            # calculate loss\n",
    "            g_loss = self.adversarial_loss(fake_predictions, real_targets)\n",
    "                                    \n",
    "            self.log(\"g_loss\", g_loss.detach(), prog_bar=True, logger=True)\n",
    "\n",
    "            return g_loss\n",
    "        \n",
    "        if optimizer_idx == 1:\n",
    "            \n",
    "            # pass in real image to D and try to make it predict all 1s\n",
    "            real_targets = torch.ones(images.size(0), 1).type_as(images) # ensuring it's on device\n",
    "            real_predictions = self.discriminator(images)\n",
    "            real_loss = self.adversarial_loss(real_predictions, real_targets)\n",
    "            real_acc = torch.mean(real_predictions).item() # the average prediction. The closer to 1 the more accurate\n",
    "            \n",
    "            # meanwhile, we also want D to be able to tell that outputs from G are all fake\n",
    "            fake_targets = torch.zeros(images.size(0), 1).type_as(images) # ensuring it's on device\n",
    "            fake_images = self.generator(noise).detach() # detach so that gradients don't pass back into generator\n",
    "            fake_predictions = self.discriminator(fake_images)\n",
    "            fake_loss = self.adversarial_loss(fake_predictions, fake_targets)\n",
    "            fake_acc = 1 - torch.mean(fake_predictions).item() # the 1 - average prediction. The closer to 1 the more accurate\n",
    "                        \n",
    "            # discriminator loss is the average of the two losses\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            avg_acc = (real_acc + fake_acc) / 2\n",
    "        \n",
    "            self.log(\"fake_loss\", fake_loss.detach(), prog_bar=False, logger=True)\n",
    "            self.log(\"real_loss\", real_loss.detach(), prog_bar=False, logger=True)\n",
    "            self.log(\"d_loss\", d_loss.detach(), prog_bar=True, logger=True)\n",
    "            self.log(\"real_acc\", real_acc, prog_bar=False, logger=True)\n",
    "            self.log(\"fake_acc\", fake_acc, prog_bar=False, logger=True)\n",
    "            self.log(\"avg_acc\", avg_acc, prog_bar=True, logger=True)\n",
    "\n",
    "            return d_loss\n",
    "\n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        # runs after each epoch\n",
    "        noise = self.validation_noise\n",
    "        noise = noise.type_as(self.generator.model[0].weight) # ensuring it's on device\n",
    "        \n",
    "        sample_imgs = self(noise).cpu()\n",
    "        grid = torchvision.utils.make_grid(sample_imgs)\n",
    "        plt.imshow((grid.permute(1, 2, 0)+1)/2)\n",
    "        self.logger.experiment.add_image(\"generated_images_epoch_end\", grid, self.current_epoch)\n",
    "\n",
    "    def configure_optimizers(self,):\n",
    "        # define pytorch optimizers here. return [list of optimizers], [list of LR schedulers]\n",
    "        g_optimizer = torch.optim.Adam(self.generator.parameters(), lr=self.lr, betas=(self.beta1, self.beta2))\n",
    "        d_optimizer = torch.optim.Adam(self.discriminator.parameters(), lr=self.lr, betas=(self.beta1, self.beta2))\n",
    "        return [g_optimizer, d_optimizer], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0228fee4d25496bb422a7e0c363e636da60e8258e4b70dda8036e2defd0af2d7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
