{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training GANCA-3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# import stuff\n",
    "\n",
    "import data_helper\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "import torch\n",
    "import random\n",
    "from torchsummaryX import summary\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from loguru import logger as gurulogger\n",
    "gurulogger.remove()\n",
    "gurulogger.add(sys.stdout, colorize=True, format=\"<blue>{time}</blue> <level>{message}</level>\")\n",
    "gurulogger.level(\"INFO\", color=\"<red><bold>\")\n",
    "\n",
    "\n",
    "import os\n",
    "from einops import rearrange\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "BLOCK2VEC_OUT_PATH = 'output/block2vec saves/block2vec 64 dim/'\n",
    "NUM_WORKERS = int(os.cpu_count() / 2)\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "    print('CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding, mcid2block, block2embeddingidx, embeddingidx2block = utils.get_embedding_info(BLOCK2VEC_OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_helper import GANCA3DDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import VoxelPerceptionNet, VoxelUpdateNet, VoxelNCAModel, VoxelDiscriminator\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "# %tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANCA(pl.LightningModule):\n",
    "\n",
    "    def __init__(self,\n",
    "            lr = 2e-4,\n",
    "            beta1 = 0.9,\n",
    "            beta2 = 0.999,\n",
    "            batch_size = 16,\n",
    "            num_embedding_channels = 64,\n",
    "            num_hidden_channels = 63,\n",
    "            update_net_channel_dims = [32, 32],\n",
    "            embedding: torch.nn.Embedding = None,\n",
    "            step_range = [16, 20],\n",
    "        ):\n",
    "        \n",
    "        super().__init__()\n",
    "        # call this to save args to the checkpoint\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.batch_size = batch_size\n",
    "        self.num_embedding_channels = num_embedding_channels\n",
    "        self.num_hidden_channels = num_hidden_channels\n",
    "        self.update_net_channel_dims = update_net_channel_dims\n",
    "        # the channels will be like [alpha, embeddings ... , hiddens ...]\n",
    "        self.num_channels = 1 + self.num_embedding_channels + self.num_hidden_channels\n",
    "        self.world_size = (32,32,32)\n",
    "        self.embedding = embedding\n",
    "        self.step_range = step_range\n",
    "        \n",
    "        self.generator = VoxelNCAModel(\n",
    "            alpha_living_threshold = 0.1,\n",
    "            cell_fire_rate = 0.5,\n",
    "            num_perceptions = 3,\n",
    "            perception_requires_grad = True,\n",
    "            num_embedding_channels = self.num_embedding_channels,\n",
    "            num_hidden_channels = self.num_hidden_channels,\n",
    "            normal_std = 0.0002,\n",
    "            use_normal_init = True,\n",
    "            zero_bias = True,\n",
    "            update_net_channel_dims = self.update_net_channel_dims,\n",
    "        )\n",
    "        self.discriminator = VoxelDiscriminator(\n",
    "            num_in_channels = self.num_embedding_channels, \n",
    "            use_sigmoid=True,\n",
    "        )\n",
    "        \n",
    "        # generate some random seeds (N, channels, x, y, z)\n",
    "        self.validation_noise = self.make_seed_states(16)\n",
    "        \n",
    "    def make_seed_states(self, batch_size):\n",
    "        return utils.make_seed_state(\n",
    "            batch_size = batch_size,\n",
    "            num_channels = self.num_channels, \n",
    "            alpha_channel_index = 0,\n",
    "            seed_dim = (4, 4, 4), \n",
    "            world_size = self.world_size,\n",
    "        )\n",
    "    \n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        \n",
    "        num_steps = random.randint(self.step_range)\n",
    "            \n",
    "        real_houses = batch\n",
    "        type_holder = batch[0,0,0,0].to(torch.float) # this is a dummy type for creating labels\n",
    "        gurulogger.info(f'created typeholder tensor {type_holder} for new tensors with type {type_holder.type()} on device {type_holder.get_device()}')\n",
    "        size_this_batch = real_houses.shape[0]\n",
    "        gurulogger.info(f'got shape {real_houses.shape} as real example')\n",
    "                \n",
    "        # make noise\n",
    "        \n",
    "        seed_states = self.make_seed_states(size_this_batch).type_as(type_holder) # same batch size as those coming in\n",
    "        gurulogger.info(f'made seed states with shape {seed_states.shape} and type {seed_states.type()}')\n",
    "            \n",
    "        # train generator\n",
    "        if optimizer_idx == 0:\n",
    "            \n",
    "            gurulogger.info(\"ENTERING GENERATOR TRAIN LOOP\")\n",
    "\n",
    "            # generate images\n",
    "            fake_houses_states = self.generator.forward(seed_states, steps=num_steps)\n",
    "            gurulogger.info(f'generated houses of shape {fake_houses_states.shape}')\n",
    "                        \n",
    "            # create ground truth result (all fake results) we want D to say the generated ones are real so they are all 1s\n",
    "            real_labels = utils.make_real_labels(size_this_batch).type_as(type_holder)\n",
    "            gurulogger.info(f'real labels looks like: {real_labels}')\n",
    "            \n",
    "            # now get the embedding parts out of the fake states\n",
    "            fake_houses = fake_houses_states[:, 1:self.num_embedding_channels+1, :, :, :]\n",
    "            gurulogger.info(f'extracted fake_houses with shape: {fake_houses.shape}')\n",
    "            \n",
    "            # see what discriminator thinks\n",
    "            fake_predictions = self.discriminator.forward(fake_houses)\n",
    "            gurulogger.info(f\"the discriminator predicted {fake_predictions} for the houses. let's compare that to the real label {real_labels}\")\n",
    "            \n",
    "            # calculate loss\n",
    "            g_loss = F.binary_cross_entropy(fake_predictions, real_labels) # y_hat, y  \n",
    "            gurulogger.info(f'gooooooooooooooooooooooooooooooooooooooood so far for generator. step done with g_loss **{g_loss}**')\n",
    "                                    \n",
    "            self.log(\"g_loss\", g_loss.detach(), prog_bar=True, logger=True)\n",
    "\n",
    "            return g_loss\n",
    "        \n",
    "        if optimizer_idx == 1:\n",
    "            \n",
    "            gurulogger.info(\"ENTERING DISCRIMINATOR TRAIN LOOP\")\n",
    "            \n",
    "            # get embeddings for the real house\n",
    "            real_houses = utils.examples2embedding(real_houses, self.embedding)\n",
    "            \n",
    "            gurulogger.info(f\"got embedded real houses with shape {real_houses.shape}\")\n",
    "\n",
    "            # pass in real image to D and try to make it predict all 1s\n",
    "            real_targets = utils.make_real_labels(size_this_batch).type_as(type_holder)\n",
    "            real_predictions = self.discriminator.forward(real_houses)\n",
    "            gurulogger.info(f\"on a real house, D gave predictions: {real_predictions}; and we want to match the label {real_targets}\")\n",
    "            real_loss = F.binary_cross_entropy(real_predictions, real_targets)\n",
    "            real_acc = torch.mean(real_predictions > 0.5).item() # the average prediction. The closer to 1 the more accurate\n",
    "            gurulogger.info(f\"real loss is therefore: {real_loss}; and real accuracy is {real_acc}\")\n",
    "            \n",
    "            # meanwhile, we also want D to be able to tell that outputs from G are all fake\n",
    "            fake_targets = utils.make_fake_labels(size_this_batch).type_as(type_holder)\n",
    "            fake_houses_states = self.generator.forward(seed_states, steps=num_steps).detach() # detach so that gradients don't pass back into generator\n",
    "            fake_houses = fake_houses_states[:, 1:self.num_embedding_channels+1, :, :, :] # extract the embedding parts\n",
    "            gurulogger.info(f\"created fake target: {fake_targets}; generated from seeds fake houses output {fake_houses_states.shape} and extracted the embeddings to {fake_houses.shape}\")\n",
    "            fake_predictions = self.discriminator.forward(fake_houses)\n",
    "            gurulogger.info(f\"D predicted: {fake_predictions} on fake houses\")\n",
    "            fake_loss = F.binary_cross_entropy(fake_predictions, fake_targets)\n",
    "            fake_acc = 1 - torch.mean(fake_predictions < 0.5).item() # the 1 - average prediction. The closer to 1 the more accurate\n",
    "            gurulogger.info(f\"fake loss is therefore: {fake_loss}; and fake accuracy is {fake_acc}\")\n",
    "                        \n",
    "            # discriminator loss is the average of the two losses\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            avg_acc = (real_acc + fake_acc) / 2\n",
    "            gurulogger.info(f\"avg D loss is: {d_loss}; and avg accuracy is {avg_acc}\")\n",
    "                    \n",
    "            self.log(\"fake_loss\", fake_loss.detach(), prog_bar=False, logger=True)\n",
    "            self.log(\"real_loss\", real_loss.detach(), prog_bar=False, logger=True)\n",
    "            self.log(\"d_loss\", d_loss.detach(), prog_bar=True, logger=True)\n",
    "            self.log(\"real_acc\", real_acc, prog_bar=False, logger=True)\n",
    "            self.log(\"fake_acc\", fake_acc, prog_bar=False, logger=True)\n",
    "            self.log(\"avg_acc\", avg_acc, prog_bar=True, logger=True)\n",
    "\n",
    "            return d_loss\n",
    "\n",
    "    def configure_optimizers(self,):\n",
    "        # define pytorch optimizers here. return [list of optimizers], [list of LR schedulers]\n",
    "        g_optimizer = torch.optim.Adam(self.generator.parameters(), lr=self.lr, betas=(self.beta1, self.beta2))\n",
    "        d_optimizer = torch.optim.Adam(self.discriminator.parameters(), lr=self.lr, betas=(self.beta1, self.beta2))\n",
    "        return [g_optimizer, d_optimizer], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tt/63g2nkx15fl855gr711x66540000gn/T/ipykernel_13883/3269744542.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnum_hidden_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m63\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mupdate_net_channel_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0membedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mstep_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding' is not defined"
     ]
    }
   ],
   "source": [
    "model = GANCA(\n",
    "    lr = 2e-4,\n",
    "    beta1 = 0.9,\n",
    "    beta2 = 0.999,\n",
    "    batch_size = 16,\n",
    "    num_embedding_channels = 64,\n",
    "    num_hidden_channels = 63,\n",
    "    update_net_channel_dims = [16, 16],\n",
    "    embedding = embedding,\n",
    "    step_range = [16, 20],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dm = GANCA3DDataModule(batch_size=16, num_workers=1, mcid2block = mcid2block, block2embeddingid = block2embeddingidx, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "Running in fast_dev_run mode: will run a full train, val, test and prediction loop using 1 batch(es).\n"
     ]
    }
   ],
   "source": [
    "logger = pl.loggers.TensorBoardLogger(save_dir='lightning_logs', name='GANCA', default_hp_metric=False)\n",
    "trainer = Trainer(gpus=0, max_epochs=1, fast_dev_run=True, log_every_n_steps=1, logger=logger, profiler=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | embedding     | Embedding          | 14.0 K\n",
      "1 | generator     | VoxelNCAModel      | 18.8 K\n",
      "2 | discriminator | VoxelDiscriminator | 11.3 M\n",
      "-----------------------------------------------------\n",
      "11.3 M    Trainable params\n",
      "14.0 K    Non-trainable params\n",
      "11.3 M    Total params\n",
      "45.244    Total estimated model params size (MB)\n",
      "/Users/chaosarium/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \u001b[34m2022-02-28T20:32:31.099838+0800\u001b[0m \u001b[31m\u001b[1mcreated typeholder tensor 0.0 for new tensors with type torch.FloatTensor on device -1\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:31.100758+0800\u001b[0m \u001b[31m\u001b[1mgot shape torch.Size([8, 32, 32, 32]) as real example\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:31.123795+0800\u001b[0m \u001b[31m\u001b[1mmade seed states with shape torch.Size([8, 128, 32, 32, 32]) and type torch.FloatTensor\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:31.124390+0800\u001b[0m \u001b[31m\u001b[1mENTERING GENERATOR TRAIN LOOP\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:31.131597+0800\u001b[0m \u001b[31m\u001b[1mit's shape torch.Size([8, 128, 32, 32, 32]) coming in to the perception net\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:32.505888+0800\u001b[0m \u001b[33m\u001b[1mit's shape torch.Size([8, 384, 32, 32, 32]) coming in to the update net\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:33.011011+0800\u001b[0m \u001b[31m\u001b[1mgenerated houses of shape torch.Size([8, 128, 32, 32, 32])\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:33.014577+0800\u001b[0m \u001b[31m\u001b[1mreal labels looks like: tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:33.015157+0800\u001b[0m \u001b[31m\u001b[1mextracted fake_houses with shape: torch.Size([8, 64, 32, 32, 32])\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:33.991120+0800\u001b[0m \u001b[33m\u001b[1musing sigmoid for discriminator\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:33.992517+0800\u001b[0m \u001b[31m\u001b[1mthe discriminator predicted tensor([[2.7939e-06],\n",
      "        [4.2377e-06],\n",
      "        [1.1027e-05],\n",
      "        [5.6414e-06],\n",
      "        [8.4606e-06],\n",
      "        [9.5914e-06],\n",
      "        [7.8429e-06],\n",
      "        [1.2429e-05]], grad_fn=<SigmoidBackward0>) for the houses. let's compare that to the real label tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:33.993063+0800\u001b[0m \u001b[31m\u001b[1mgooooooooooooooooooooooooooooooooooooooood so far for generator. step done with g_loss **11.868284225463867**\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:37.387368+0800\u001b[0m \u001b[31m\u001b[1mcreated typeholder tensor 0.0 for new tensors with type torch.FloatTensor on device -1\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:37.387841+0800\u001b[0m \u001b[31m\u001b[1mgot shape torch.Size([8, 32, 32, 32]) as real example\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:37.393995+0800\u001b[0m \u001b[31m\u001b[1mmade seed states with shape torch.Size([8, 128, 32, 32, 32]) and type torch.FloatTensor\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:37.394529+0800\u001b[0m \u001b[31m\u001b[1mENTERING DISCRIMINATOR TRAIN LOOP\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:37.398106+0800\u001b[0m \u001b[31m\u001b[1mgot embedded real houses with shape torch.Size([8, 64, 32, 32, 32])\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:38.283494+0800\u001b[0m \u001b[33m\u001b[1musing sigmoid for discriminator\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:38.284696+0800\u001b[0m \u001b[31m\u001b[1mon a real house, D gave predictions: torch.Size([8, 1]); and we want to match the label tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:38.285142+0800\u001b[0m \u001b[31m\u001b[1mreal loss is therefore: 0.0003073172701988369; and real accuracy is 0.9996927976608276\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:38.290592+0800\u001b[0m \u001b[31m\u001b[1mit's shape torch.Size([8, 128, 32, 32, 32]) coming in to the perception net\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:39.535532+0800\u001b[0m \u001b[33m\u001b[1mit's shape torch.Size([8, 384, 32, 32, 32]) coming in to the update net\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:39.880763+0800\u001b[0m \u001b[31m\u001b[1mcreated fake target: tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]); generated from seeds fake houses output torch.Size([8, 128, 32, 32, 32]) and extracted the embeddings to torch.Size([8, 64, 32, 32, 32])\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:40.722290+0800\u001b[0m \u001b[33m\u001b[1musing sigmoid for discriminator\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:40.723373+0800\u001b[0m \u001b[31m\u001b[1mD predicted: tensor([[9.2325e-06],\n",
      "        [3.1769e-06],\n",
      "        [7.5927e-06],\n",
      "        [6.0826e-06],\n",
      "        [7.0571e-06],\n",
      "        [7.8052e-06],\n",
      "        [4.5790e-06],\n",
      "        [1.0114e-05]], grad_fn=<SigmoidBackward0>) on fake houses\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:40.723807+0800\u001b[0m \u001b[31m\u001b[1mfake loss is therefore: 6.951418527023634e-06; and fake accuracy is 0.9999930449630483\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:40.724045+0800\u001b[0m \u001b[31m\u001b[1mavg D loss is: 0.00015713434549979866; and avg accuracy is 0.999842921311938\u001b[0m\n",
      "Epoch 0: 100%|██████████| 1/1 [00:20<00:00, 20.21s/it, loss=5.93, v_num=, d_loss=0.000157, avg_acc=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  20.896         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  20.206         \t|1              \t|  20.206         \t|  96.699         \t|\n",
      "run_training_batch                 \t|  13.096         \t|1              \t|  13.096         \t|  62.675         \t|\n",
      "training_step_and_backward         \t|  6.5306         \t|2              \t|  13.061         \t|  62.507         \t|\n",
      "backward                           \t|  3.4064         \t|2              \t|  6.8128         \t|  32.604         \t|\n",
      "optimizer_step_with_closure_1      \t|  6.808          \t|1              \t|  6.808          \t|  32.581         \t|\n",
      "optimizer_step_with_closure_0      \t|  6.2872         \t|1              \t|  6.2872         \t|  30.089         \t|\n",
      "model_forward                      \t|  3.1183         \t|2              \t|  6.2366         \t|  29.846         \t|\n",
      "training_step                      \t|  3.1176         \t|2              \t|  6.2353         \t|  29.84          \t|\n",
      "get_train_batch                    \t|  2.9655         \t|2              \t|  5.931          \t|  28.384         \t|\n",
      "fetch_next_train_batch             \t|  2.9655         \t|2              \t|  5.9309         \t|  28.384         \t|\n",
      "zero_grad                          \t|  0.0058888      \t|2              \t|  0.011778       \t|  0.056364       \t|\n",
      "on_train_batch_end                 \t|  0.0015986      \t|1              \t|  0.0015986      \t|  0.0076503      \t|\n",
      "on_pretrain_routine_start          \t|  0.0010976      \t|1              \t|  0.0010976      \t|  0.0052527      \t|\n",
      "on_train_start                     \t|  0.00073413     \t|1              \t|  0.00073413     \t|  0.0035133      \t|\n",
      "on_train_epoch_start               \t|  0.00063254     \t|1              \t|  0.00063254     \t|  0.0030271      \t|\n",
      "on_train_epoch_end                 \t|  0.00049975     \t|1              \t|  0.00049975     \t|  0.0023917      \t|\n",
      "training_batch_to_device           \t|  0.00043792     \t|1              \t|  0.00043792     \t|  0.0020957      \t|\n",
      "on_train_end                       \t|  0.00040638     \t|1              \t|  0.00040638     \t|  0.0019448      \t|\n",
      "on_train_batch_start               \t|  0.00012496     \t|1              \t|  0.00012496     \t|  0.00059802     \t|\n",
      "configure_optimizers               \t|  9.2333e-05     \t|1              \t|  9.2333e-05     \t|  0.00044188     \t|\n",
      "on_before_zero_grad                \t|  4.0521e-05     \t|2              \t|  8.1042e-05     \t|  0.00038784     \t|\n",
      "on_after_backward                  \t|  2.2563e-05     \t|2              \t|  4.5125e-05     \t|  0.00021595     \t|\n",
      "on_batch_start                     \t|  3.6167e-05     \t|1              \t|  3.6167e-05     \t|  0.00017308     \t|\n",
      "on_before_backward                 \t|  1.6146e-05     \t|2              \t|  3.2291e-05     \t|  0.00015453     \t|\n",
      "teardown                           \t|  2.6833e-05     \t|1              \t|  2.6833e-05     \t|  0.00012841     \t|\n",
      "on_batch_end                       \t|  2.4375e-05     \t|1              \t|  2.4375e-05     \t|  0.00011665     \t|\n",
      "on_before_optimizer_step           \t|  9.854e-06      \t|2              \t|  1.9708e-05     \t|  9.4316e-05     \t|\n",
      "training_step_end                  \t|  7.25e-06       \t|2              \t|  1.45e-05       \t|  6.9393e-05     \t|\n",
      "on_fit_end                         \t|  1.2917e-05     \t|1              \t|  1.2917e-05     \t|  6.1817e-05     \t|\n",
      "on_epoch_end                       \t|  1.0417e-05     \t|1              \t|  1.0417e-05     \t|  4.9853e-05     \t|\n",
      "on_configure_sharded_model         \t|  9.666e-06      \t|1              \t|  9.666e-06      \t|  4.6259e-05     \t|\n",
      "on_before_accelerator_backend_setup\t|  9.459e-06      \t|1              \t|  9.459e-06      \t|  4.5268e-05     \t|\n",
      "on_epoch_start                     \t|  8.375e-06      \t|1              \t|  8.375e-06      \t|  4.008e-05      \t|\n",
      "on_fit_start                       \t|  8.042e-06      \t|1              \t|  8.042e-06      \t|  3.8487e-05     \t|\n",
      "on_pretrain_routine_end            \t|  7.292e-06      \t|1              \t|  7.292e-06      \t|  3.4897e-05     \t|\n",
      "setup                              \t|  7e-06          \t|1              \t|  7e-06          \t|  3.35e-05       \t|\n",
      "configure_callbacks                \t|  4.125e-06      \t|1              \t|  4.125e-06      \t|  1.9741e-05     \t|\n",
      "configure_sharded_model            \t|  3.625e-06      \t|1              \t|  3.625e-06      \t|  1.7348e-05     \t|\n",
      "prepare_data                       \t|  3.042e-06      \t|1              \t|  3.042e-06      \t|  1.4558e-05     \t|\n",
      "on_train_dataloader                \t|  3e-06          \t|1              \t|  3e-06          \t|  1.4357e-05     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "debug\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_state = torch.rand(1, 128, 32, 32, 32)\n",
    "sample_seed_state = utils.make_seed_state(\n",
    "    batch_size = 1,\n",
    "    num_channels = 128, \n",
    "    alpha_channel_index = 0,\n",
    "    seed_dim = (4, 4, 4), \n",
    "    world_size = (32,32,32),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2022-02-28T20:32:09.898136+0800\u001b[0m \u001b[31m\u001b[1mit's shape torch.Size([1, 128, 32, 32, 32]) coming in to the perception net\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:10.059550+0800\u001b[0m \u001b[33m\u001b[1mit's shape torch.Size([1, 384, 32, 32, 32]) coming in to the update net\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2097196.2500, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before train\n",
    "out1 = model.generator.forward(sample_state, steps=1)\n",
    "torch.sum(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2022-02-28T20:32:54.688500+0800\u001b[0m \u001b[31m\u001b[1mit's shape torch.Size([1, 128, 32, 32, 32]) coming in to the perception net\u001b[0m\n",
      "\u001b[34m2022-02-28T20:32:54.819261+0800\u001b[0m \u001b[33m\u001b[1mit's shape torch.Size([1, 384, 32, 32, 32]) coming in to the update net\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2097196.2500, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after train\n",
    "out3 = model.generator.forward(sample_state, steps=1)\n",
    "torch.sum(out3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(out1, out3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2097251.2500, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2 = model.generator.forward(sample_state, steps=8)\n",
    "torch.sum(out2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0228fee4d25496bb422a7e0c363e636da60e8258e4b70dda8036e2defd0af2d7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
